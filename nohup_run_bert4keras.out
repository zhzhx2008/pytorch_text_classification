nohup: ignoring input
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_base/model.ckpt-best', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_base/albert_config.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_base/vocab_chinese.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_finance': 0, 'news_car': 1, 'news_story': 2, 'news_tech': 3, 'news_entertainment': 4, 'news_agriculture': 5, 'news_culture': 6, 'news_house': 7, 'news_travel': 8, 'news_military': 9, 'news_game': 10, 'news_sports': 11, 'news_stock': 12, 'news_world': 13, 'news_edu': 14}
index_labels_dict={0: 'news_finance', 1: 'news_car', 2: 'news_story', 3: 'news_tech', 4: 'news_entertainment', 5: 'news_agriculture', 6: 'news_culture', 7: 'news_house', 8: 'news_travel', 9: 'news_military', 10: 'news_game', 11: 'news_sports', 12: 'news_stock', 13: 'news_world', 14: 'news_edu'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 01:52:53.756742: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 01:52:55.010741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 128)    2704384     Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 128)    256         Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 128)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 128)    65536       Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 128)    256         Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Mapping (Dense)       (None, None, 768)    99072       Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 768)    2362368     Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 768)    0           Embedding-Mapping[0][0]          
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 768)    1536        Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 768)    4722432     Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 768)    0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[4][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[5][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[6][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[7][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[8][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[9][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[10][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[11][0]   
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 768)    1536        Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
                                                                 Transformer-FeedForward-Add[4][0]
                                                                 Transformer-FeedForward-Add[5][0]
                                                                 Transformer-FeedForward-Add[6][0]
                                                                 Transformer-FeedForward-Add[7][0]
                                                                 Transformer-FeedForward-Add[8][0]
                                                                 Transformer-FeedForward-Add[9][0]
                                                                 Transformer-FeedForward-Add[10][0
                                                                 Transformer-FeedForward-Add[11][0
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 768)          0           Transformer-FeedForward-Norm[11][
__________________________________________________________________________________________________
dropout (Dropout)               (None, 768)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           11535       dropout[0][0]                    
==================================================================================================
Total params: 9,968,911
Trainable params: 9,968,911
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 01:52:57.499227: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 219s - loss: 2.6153 - accuracy: 0.1046
dev acc=11.15%
test acc=10.89%
Epoch 2/10000
751/751 - 206s - loss: 2.6092 - accuracy: 0.1043
dev acc=11.15%
Epoch 3/10000
751/751 - 207s - loss: 2.6072 - accuracy: 0.1064
dev acc=11.15%
Epoch 4/10000
751/751 - 207s - loss: 2.6072 - accuracy: 0.1060
dev acc=11.15%
Epoch 5/10000
751/751 - 207s - loss: 2.6065 - accuracy: 0.1064
dev acc=11.15%
Epoch 6/10000
751/751 - 207s - loss: 2.6065 - accuracy: 0.1070
dev acc=11.15%
time used=1428.2s
2022-05-12 02:16:37.347353: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_large/model.ckpt-best', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_large/albert_config.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_large/vocab_chinese.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_game': 0, 'news_military': 1, 'news_travel': 2, 'news_agriculture': 3, 'news_finance': 4, 'news_culture': 5, 'news_house': 6, 'news_stock': 7, 'news_entertainment': 8, 'news_car': 9, 'news_story': 10, 'news_tech': 11, 'news_world': 12, 'news_edu': 13, 'news_sports': 14}
index_labels_dict={0: 'news_game', 1: 'news_military', 2: 'news_travel', 3: 'news_agriculture', 4: 'news_finance', 5: 'news_culture', 6: 'news_house', 7: 'news_stock', 8: 'news_entertainment', 9: 'news_car', 10: 'news_story', 11: 'news_tech', 12: 'news_world', 13: 'news_edu', 14: 'news_sports'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 02:16:46.067401: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 02:16:47.258205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 128)    2704384     Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 128)    256         Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 128)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 128)    65536       Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 128)    256         Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Mapping (Dense)       (None, None, 1024)   132096      Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 1024)   4198400     Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-FeedForward-Norm[22][
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 1024)   0           Embedding-Mapping[0][0]          
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 1024)   2048        Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 1024)   8393728     Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 1024)   0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[4][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[5][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[6][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[7][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[8][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[9][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[10][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[11][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[12][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[13][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[14][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[15][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[16][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[17][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[18][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[19][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[20][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[21][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[22][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[23][0]   
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 1024)   2048        Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
                                                                 Transformer-FeedForward-Add[4][0]
                                                                 Transformer-FeedForward-Add[5][0]
                                                                 Transformer-FeedForward-Add[6][0]
                                                                 Transformer-FeedForward-Add[7][0]
                                                                 Transformer-FeedForward-Add[8][0]
                                                                 Transformer-FeedForward-Add[9][0]
                                                                 Transformer-FeedForward-Add[10][0
                                                                 Transformer-FeedForward-Add[11][0
                                                                 Transformer-FeedForward-Add[12][0
                                                                 Transformer-FeedForward-Add[13][0
                                                                 Transformer-FeedForward-Add[14][0
                                                                 Transformer-FeedForward-Add[15][0
                                                                 Transformer-FeedForward-Add[16][0
                                                                 Transformer-FeedForward-Add[17][0
                                                                 Transformer-FeedForward-Add[18][0
                                                                 Transformer-FeedForward-Add[19][0
                                                                 Transformer-FeedForward-Add[20][0
                                                                 Transformer-FeedForward-Add[21][0
                                                                 Transformer-FeedForward-Add[22][0
                                                                 Transformer-FeedForward-Add[23][0
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 1024)         0           Transformer-FeedForward-Norm[23][
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1024)         0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           15375       dropout[0][0]                    
==================================================================================================
Total params: 15,514,127
Trainable params: 15,514,127
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 02:16:51.227655: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 635s - loss: 2.6244 - accuracy: 0.1014
dev acc=11.15%
test acc=10.89%
Epoch 2/10000
751/751 - 611s - loss: 2.6086 - accuracy: 0.1058
dev acc=11.15%
Epoch 3/10000
751/751 - 611s - loss: 2.6085 - accuracy: 0.1061
dev acc=11.15%
Epoch 4/10000
751/751 - 613s - loss: 2.6088 - accuracy: 0.1063
dev acc=11.15%
Epoch 5/10000
751/751 - 613s - loss: 2.6095 - accuracy: 0.1062
dev acc=11.15%
Epoch 6/10000
751/751 - 613s - loss: 2.6088 - accuracy: 0.1054
dev acc=11.15%
time used=3997.1s
2022-05-12 03:23:18.771739: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_xlarge/model.ckpt-best', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_xlarge/albert_config.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_xlarge/vocab_chinese.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_world': 0, 'news_military': 1, 'news_game': 2, 'news_sports': 3, 'news_car': 4, 'news_agriculture': 5, 'news_entertainment': 6, 'news_stock': 7, 'news_tech': 8, 'news_travel': 9, 'news_house': 10, 'news_finance': 11, 'news_edu': 12, 'news_story': 13, 'news_culture': 14}
index_labels_dict={0: 'news_world', 1: 'news_military', 2: 'news_game', 3: 'news_sports', 4: 'news_car', 5: 'news_agriculture', 6: 'news_entertainment', 7: 'news_stock', 8: 'news_tech', 9: 'news_travel', 10: 'news_house', 11: 'news_finance', 12: 'news_edu', 13: 'news_story', 14: 'news_culture'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 03:23:27.540419: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 03:23:28.305861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 128)    2704384     Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 128)    256         Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 128)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 128)    65536       Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 128)    256         Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Mapping (Dense)       (None, None, 2048)   264192      Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 2048)   16785408    Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-FeedForward-Norm[22][
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 2048)   0           Embedding-Mapping[0][0]          
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 2048)   4096        Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 2048)   33564672    Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 2048)   0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[4][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[5][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[6][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[7][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[8][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[9][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[10][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[11][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[12][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[13][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[14][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[15][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[16][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[17][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[18][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[19][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[20][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[21][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[22][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[23][0]   
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 2048)   4096        Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
                                                                 Transformer-FeedForward-Add[4][0]
                                                                 Transformer-FeedForward-Add[5][0]
                                                                 Transformer-FeedForward-Add[6][0]
                                                                 Transformer-FeedForward-Add[7][0]
                                                                 Transformer-FeedForward-Add[8][0]
                                                                 Transformer-FeedForward-Add[9][0]
                                                                 Transformer-FeedForward-Add[10][0
                                                                 Transformer-FeedForward-Add[11][0
                                                                 Transformer-FeedForward-Add[12][0
                                                                 Transformer-FeedForward-Add[13][0
                                                                 Transformer-FeedForward-Add[14][0
                                                                 Transformer-FeedForward-Add[15][0
                                                                 Transformer-FeedForward-Add[16][0
                                                                 Transformer-FeedForward-Add[17][0
                                                                 Transformer-FeedForward-Add[18][0
                                                                 Transformer-FeedForward-Add[19][0
                                                                 Transformer-FeedForward-Add[20][0
                                                                 Transformer-FeedForward-Add[21][0
                                                                 Transformer-FeedForward-Add[22][0
                                                                 Transformer-FeedForward-Add[23][0
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 2048)         0           Transformer-FeedForward-Norm[23][
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           30735       dropout[0][0]                    
==================================================================================================
Total params: 53,423,631
Trainable params: 53,423,631
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 03:23:32.720677: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 1946s - loss: 2.6708 - accuracy: 0.0956
dev acc=9.09%
test acc=9.05%
Epoch 2/10000
751/751 - 1936s - loss: 2.6206 - accuracy: 0.1008
dev acc=9.09%
Epoch 3/10000
751/751 - 1937s - loss: 2.6161 - accuracy: 0.1028
dev acc=9.75%
test acc=9.56%
Epoch 4/10000
751/751 - 1937s - loss: 2.6140 - accuracy: 0.1047
dev acc=11.15%
test acc=10.89%
Epoch 5/10000
751/751 - 1939s - loss: 2.6134 - accuracy: 0.1048
dev acc=11.15%
Epoch 6/10000
751/751 - 1939s - loss: 2.6125 - accuracy: 0.1046
dev acc=11.15%
Epoch 7/10000
751/751 - 1938s - loss: 2.6123 - accuracy: 0.1046
dev acc=11.15%
Epoch 8/10000
751/751 - 1939s - loss: 2.6114 - accuracy: 0.1052
dev acc=11.15%
Epoch 9/10000
751/751 - 1939s - loss: 2.6111 - accuracy: 0.1053
dev acc=11.15%
time used=18711.6s
2022-05-12 08:35:14.697423: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_xxlarge/model.ckpt-best', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_xxlarge/albert_config.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert/albert_xxlarge/vocab_chinese.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_finance': 0, 'news_military': 1, 'news_entertainment': 2, 'news_culture': 3, 'news_edu': 4, 'news_game': 5, 'news_car': 6, 'news_tech': 7, 'news_house': 8, 'news_travel': 9, 'news_world': 10, 'news_sports': 11, 'news_agriculture': 12, 'news_story': 13, 'news_stock': 14}
index_labels_dict={0: 'news_finance', 1: 'news_military', 2: 'news_entertainment', 3: 'news_culture', 4: 'news_edu', 5: 'news_game', 6: 'news_car', 7: 'news_tech', 8: 'news_house', 9: 'news_travel', 10: 'news_world', 11: 'news_sports', 12: 'news_agriculture', 13: 'news_story', 14: 'news_stock'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 08:35:23.452711: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 08:35:24.273945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 128)    2704384     Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 128)    256         Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 128)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 128)    65536       Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 128)    256         Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Mapping (Dense)       (None, None, 4096)   528384      Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 4096)   67125248    Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 4096)   0           Embedding-Mapping[0][0]          
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 4096)   8192        Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 4096)   134238208   Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 4096)   0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[4][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[5][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[6][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[7][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[8][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[9][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[10][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[11][0]   
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 4096)   8192        Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
                                                                 Transformer-FeedForward-Add[4][0]
                                                                 Transformer-FeedForward-Add[5][0]
                                                                 Transformer-FeedForward-Add[6][0]
                                                                 Transformer-FeedForward-Add[7][0]
                                                                 Transformer-FeedForward-Add[8][0]
                                                                 Transformer-FeedForward-Add[9][0]
                                                                 Transformer-FeedForward-Add[10][0
                                                                 Transformer-FeedForward-Add[11][0
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 4096)         0           Transformer-FeedForward-Norm[11][
__________________________________________________________________________________________________
dropout (Dropout)               (None, 4096)         0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           61455       dropout[0][0]                    
==================================================================================================
Total params: 204,740,111
Trainable params: 204,740,111
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 08:35:28.989967: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 3616s - loss: 2.6902 - accuracy: 0.0940
dev acc=9.09%
test acc=9.05%
Epoch 2/10000
751/751 - 3635s - loss: 2.6312 - accuracy: 0.0991
dev acc=9.09%
Epoch 3/10000
751/751 - 3627s - loss: 2.6269 - accuracy: 0.1000
dev acc=9.09%
Epoch 4/10000
751/751 - 3622s - loss: 2.6205 - accuracy: 0.1035
dev acc=9.09%
Epoch 5/10000
751/751 - 3606s - loss: 2.6192 - accuracy: 0.1029
dev acc=9.09%
Epoch 6/10000
751/751 - 3615s - loss: 2.6183 - accuracy: 0.1024
dev acc=9.09%
time used=22859.6s
2022-05-12 14:56:18.300858: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_base_google_zh_additional_36k_steps/albert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_base_google_zh_additional_36k_steps/albert_config.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_base_google_zh_additional_36k_steps/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_game': 0, 'news_travel': 1, 'news_culture': 2, 'news_agriculture': 3, 'news_world': 4, 'news_story': 5, 'news_edu': 6, 'news_entertainment': 7, 'news_military': 8, 'news_house': 9, 'news_stock': 10, 'news_car': 11, 'news_tech': 12, 'news_sports': 13, 'news_finance': 14}
index_labels_dict={0: 'news_game', 1: 'news_travel', 2: 'news_culture', 3: 'news_agriculture', 4: 'news_world', 5: 'news_story', 6: 'news_edu', 7: 'news_entertainment', 8: 'news_military', 9: 'news_house', 10: 'news_stock', 11: 'news_car', 12: 'news_tech', 13: 'news_sports', 14: 'news_finance'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 14:56:27.103422: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 14:56:27.898664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 768)    2362368     Embedding-Norm[0][0]             
                                                                 Embedding-Norm[0][0]             
                                                                 Embedding-Norm[0][0]             
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 768)    0           Embedding-Norm[0][0]             
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 768)    1536        Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 768)    4722432     Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 768)    0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[4][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[5][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[6][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[7][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[8][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[9][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[10][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[11][0]   
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 768)    1536        Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
                                                                 Transformer-FeedForward-Add[4][0]
                                                                 Transformer-FeedForward-Add[5][0]
                                                                 Transformer-FeedForward-Add[6][0]
                                                                 Transformer-FeedForward-Add[7][0]
                                                                 Transformer-FeedForward-Add[8][0]
                                                                 Transformer-FeedForward-Add[9][0]
                                                                 Transformer-FeedForward-Add[10][0
                                                                 Transformer-FeedForward-Add[11][0
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 768)          0           Transformer-FeedForward-Norm[11][
__________________________________________________________________________________________________
dropout (Dropout)               (None, 768)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           11535       dropout[0][0]                    
==================================================================================================
Total params: 23,721,999
Trainable params: 23,721,999
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 14:56:30.572152: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 270s - loss: 2.6307 - accuracy: 0.1001
dev acc=9.09%
test acc=9.05%
Epoch 2/10000
751/751 - 257s - loss: 2.6468 - accuracy: 0.1003
dev acc=9.09%
Epoch 3/10000
751/751 - 256s - loss: 2.6214 - accuracy: 0.1010
dev acc=11.15%
test acc=10.89%
Epoch 4/10000
751/751 - 257s - loss: 2.7181 - accuracy: 0.0915
dev acc=9.09%
Epoch 5/10000
751/751 - 257s - loss: 2.6424 - accuracy: 0.0964
dev acc=9.75%
Epoch 6/10000
751/751 - 257s - loss: 2.6130 - accuracy: 0.1038
dev acc=11.15%
Epoch 7/10000
751/751 - 257s - loss: 2.6070 - accuracy: 0.1061
dev acc=11.15%
Epoch 8/10000
751/751 - 257s - loss: 2.6058 - accuracy: 0.1064
dev acc=11.15%
time used=2306.7s
2022-05-12 15:34:49.403903: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_large_google_zh/albert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_large_google_zh/albert_config.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_large_google_zh/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_house': 0, 'news_game': 1, 'news_culture': 2, 'news_entertainment': 3, 'news_tech': 4, 'news_world': 5, 'news_stock': 6, 'news_sports': 7, 'news_finance': 8, 'news_travel': 9, 'news_car': 10, 'news_agriculture': 11, 'news_story': 12, 'news_military': 13, 'news_edu': 14}
index_labels_dict={0: 'news_house', 1: 'news_game', 2: 'news_culture', 3: 'news_entertainment', 4: 'news_tech', 5: 'news_world', 6: 'news_stock', 7: 'news_sports', 8: 'news_finance', 9: 'news_travel', 10: 'news_car', 11: 'news_agriculture', 12: 'news_story', 13: 'news_military', 14: 'news_edu'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 15:34:58.144019: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 15:34:58.946940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 1024)   21635072    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 1024)   2048        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 1024)   0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 1024)   524288      Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 1024)   2048        Embedding-Position[0][0]         
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 1024)   4198400     Embedding-Norm[0][0]             
                                                                 Embedding-Norm[0][0]             
                                                                 Embedding-Norm[0][0]             
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-FeedForward-Norm[22][
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 1024)   0           Embedding-Norm[0][0]             
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 1024)   2048        Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 1024)   8393728     Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 1024)   0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[4][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[5][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[6][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[7][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[8][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[9][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[10][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[11][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[12][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[13][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[14][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[15][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[16][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[17][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[18][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[19][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[20][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[21][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[22][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[23][0]   
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 1024)   2048        Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
                                                                 Transformer-FeedForward-Add[4][0]
                                                                 Transformer-FeedForward-Add[5][0]
                                                                 Transformer-FeedForward-Add[6][0]
                                                                 Transformer-FeedForward-Add[7][0]
                                                                 Transformer-FeedForward-Add[8][0]
                                                                 Transformer-FeedForward-Add[9][0]
                                                                 Transformer-FeedForward-Add[10][0
                                                                 Transformer-FeedForward-Add[11][0
                                                                 Transformer-FeedForward-Add[12][0
                                                                 Transformer-FeedForward-Add[13][0
                                                                 Transformer-FeedForward-Add[14][0
                                                                 Transformer-FeedForward-Add[15][0
                                                                 Transformer-FeedForward-Add[16][0
                                                                 Transformer-FeedForward-Add[17][0
                                                                 Transformer-FeedForward-Add[18][0
                                                                 Transformer-FeedForward-Add[19][0
                                                                 Transformer-FeedForward-Add[20][0
                                                                 Transformer-FeedForward-Add[21][0
                                                                 Transformer-FeedForward-Add[22][0
                                                                 Transformer-FeedForward-Add[23][0
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 1024)         0           Transformer-FeedForward-Norm[23][
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1024)         0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           15375       dropout[0][0]                    
==================================================================================================
Total params: 34,775,055
Trainable params: 34,775,055
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 15:35:03.403678: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 765s - loss: 2.6441 - accuracy: 0.0970
dev acc=9.09%
test acc=9.05%
Epoch 2/10000
751/751 - 741s - loss: 2.6191 - accuracy: 0.1035
dev acc=9.09%
Epoch 3/10000
751/751 - 741s - loss: 2.6152 - accuracy: 0.1042
dev acc=11.15%
test acc=10.89%
Epoch 4/10000
751/751 - 742s - loss: 2.6132 - accuracy: 0.1053
dev acc=11.15%
Epoch 5/10000
751/751 - 744s - loss: 2.6120 - accuracy: 0.1039
dev acc=11.15%
Epoch 6/10000
751/751 - 744s - loss: 2.6103 - accuracy: 0.1039
dev acc=11.15%
Epoch 7/10000
751/751 - 745s - loss: 2.6094 - accuracy: 0.1059
dev acc=11.15%
Epoch 8/10000
751/751 - 744s - loss: 2.6088 - accuracy: 0.1067
dev acc=11.15%
time used=6471.9s
2022-05-12 17:22:45.410353: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_small_zh_google/albert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_small_zh_google/albert_config_small_google.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_small_zh_google/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_car': 0, 'news_agriculture': 1, 'news_sports': 2, 'news_game': 3, 'news_entertainment': 4, 'news_culture': 5, 'news_finance': 6, 'news_stock': 7, 'news_travel': 8, 'news_world': 9, 'news_tech': 10, 'news_edu': 11, 'news_house': 12, 'news_story': 13, 'news_military': 14}
index_labels_dict={0: 'news_car', 1: 'news_agriculture', 2: 'news_sports', 3: 'news_game', 4: 'news_entertainment', 5: 'news_culture', 6: 'news_finance', 7: 'news_stock', 8: 'news_travel', 9: 'news_world', 10: 'news_tech', 11: 'news_edu', 12: 'news_house', 13: 'news_story', 14: 'news_military'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 17:22:54.697311: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 17:22:55.659691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 128)    2704384     Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 128)    256         Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 128)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 128)    65536       Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 128)    256         Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Mapping (Dense)       (None, None, 384)    49536       Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 384)    591360      Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 384)    0           Embedding-Mapping[0][0]          
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 384)    768         Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 384)    1181568     Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 384)    0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[4][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[5][0]    
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 384)    768         Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
                                                                 Transformer-FeedForward-Add[4][0]
                                                                 Transformer-FeedForward-Add[5][0]
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 384)          0           Transformer-FeedForward-Norm[5][0
__________________________________________________________________________________________________
dropout (Dropout)               (None, 384)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           5775        dropout[0][0]                    
==================================================================================================
Total params: 4,600,207
Trainable params: 4,600,207
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 17:22:57.370907: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 67s - loss: 2.4937 - accuracy: 0.1447
dev acc=15.16%
test acc=15.23%
Epoch 2/10000
751/751 - 59s - loss: 2.6087 - accuracy: 0.1080
dev acc=11.15%
Epoch 3/10000
751/751 - 59s - loss: 2.6070 - accuracy: 0.1073
dev acc=11.15%
Epoch 4/10000
751/751 - 58s - loss: 2.6067 - accuracy: 0.1075
dev acc=11.15%
Epoch 5/10000
751/751 - 58s - loss: 2.6061 - accuracy: 0.1067
dev acc=11.15%
Epoch 6/10000
751/751 - 58s - loss: 2.6062 - accuracy: 0.1073
dev acc=11.15%
time used=443.2s
2022-05-12 17:30:13.111249: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_tiny_google_zh_489k/albert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_tiny_google_zh_489k/albert_config.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_tiny_google_zh_489k/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_entertainment': 0, 'news_tech': 1, 'news_house': 2, 'news_game': 3, 'news_travel': 4, 'news_car': 5, 'news_stock': 6, 'news_edu': 7, 'news_military': 8, 'news_world': 9, 'news_agriculture': 10, 'news_culture': 11, 'news_sports': 12, 'news_story': 13, 'news_finance': 14}
index_labels_dict={0: 'news_entertainment', 1: 'news_tech', 2: 'news_house', 3: 'news_game', 4: 'news_travel', 5: 'news_car', 6: 'news_stock', 7: 'news_edu', 8: 'news_military', 9: 'news_world', 10: 'news_agriculture', 11: 'news_culture', 12: 'news_sports', 13: 'news_story', 14: 'news_finance'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 17:30:22.122269: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 17:30:23.034060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 312)    6591936     Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 312)    624         Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 312)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 312)    159744      Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 312)    624         Embedding-Position[0][0]         
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    390624      Embedding-Norm[0][0]             
                                                                 Embedding-Norm[0][0]             
                                                                 Embedding-Norm[0][0]             
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    0           Embedding-Norm[0][0]             
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    624         Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 312)    780312      Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 312)    0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 312)    624         Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 312)          0           Transformer-FeedForward-Norm[3][0
__________________________________________________________________________________________________
dropout (Dropout)               (None, 312)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           4695        dropout[0][0]                    
==================================================================================================
Total params: 7,929,807
Trainable params: 7,929,807
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 17:30:24.491596: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 43s - loss: 1.7574 - accuracy: 0.4473
dev acc=48.24%
test acc=48.93%
Epoch 2/10000
751/751 - 36s - loss: 1.5502 - accuracy: 0.5088
dev acc=48.44%
test acc=49.87%
Epoch 3/10000
751/751 - 36s - loss: 1.4445 - accuracy: 0.5404
dev acc=49.46%
test acc=49.41%
Epoch 4/10000
751/751 - 37s - loss: 1.3779 - accuracy: 0.5611
dev acc=48.74%
Epoch 5/10000
751/751 - 37s - loss: 1.3098 - accuracy: 0.5826
dev acc=49.31%
Epoch 6/10000
751/751 - 37s - loss: 1.2332 - accuracy: 0.6066
dev acc=49.31%
Epoch 7/10000
751/751 - 36s - loss: 1.1548 - accuracy: 0.6304
dev acc=50.24%
test acc=50.04%
Epoch 8/10000
751/751 - 37s - loss: 1.0996 - accuracy: 0.6496
dev acc=49.36%
Epoch 9/10000
751/751 - 37s - loss: 1.0237 - accuracy: 0.6745
dev acc=50.49%
test acc=49.26%
Epoch 10/10000
751/751 - 37s - loss: 0.9485 - accuracy: 0.7009
dev acc=48.86%
Epoch 11/10000
751/751 - 36s - loss: 0.8889 - accuracy: 0.7212
dev acc=49.74%
Epoch 12/10000
751/751 - 37s - loss: 0.8358 - accuracy: 0.7402
dev acc=48.99%
Epoch 13/10000
751/751 - 37s - loss: 0.7790 - accuracy: 0.7570
dev acc=48.89%
Epoch 14/10000
751/751 - 36s - loss: 0.7203 - accuracy: 0.7775
dev acc=48.44%
time used=701.5s
2022-05-12 17:41:58.592737: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_tiny_zh_google/albert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_tiny_zh_google/albert_config_tiny_g.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_tiny_zh_google/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_stock': 0, 'news_world': 1, 'news_car': 2, 'news_finance': 3, 'news_sports': 4, 'news_travel': 5, 'news_entertainment': 6, 'news_edu': 7, 'news_tech': 8, 'news_military': 9, 'news_culture': 10, 'news_game': 11, 'news_agriculture': 12, 'news_story': 13, 'news_house': 14}
index_labels_dict={0: 'news_stock', 1: 'news_world', 2: 'news_car', 3: 'news_finance', 4: 'news_sports', 5: 'news_travel', 6: 'news_entertainment', 7: 'news_edu', 8: 'news_tech', 9: 'news_military', 10: 'news_culture', 11: 'news_game', 12: 'news_agriculture', 13: 'news_story', 14: 'news_house'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 17:42:07.001412: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 17:42:07.897760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 128)    2704384     Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 128)    256         Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 128)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 128)    65536       Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 128)    256         Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Mapping (Dense)       (None, None, 312)    40248       Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    390624      Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Embedding-Mapping[0][0]          
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    0           Embedding-Mapping[0][0]          
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 312)    624         Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 312)    780312      Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 312)    0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 312)    624         Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 312)          0           Transformer-FeedForward-Norm[3][0
__________________________________________________________________________________________________
dropout (Dropout)               (None, 312)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           4695        dropout[0][0]                    
==================================================================================================
Total params: 3,987,559
Trainable params: 3,987,559
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 17:42:09.416883: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
751/751 - 42s - loss: 1.8023 - accuracy: 0.4321
dev acc=45.37%
test acc=45.08%
Epoch 2/10000
751/751 - 35s - loss: 1.7013 - accuracy: 0.4692
dev acc=42.86%
Epoch 3/10000
751/751 - 35s - loss: 1.7407 - accuracy: 0.4564
dev acc=43.29%
Epoch 4/10000
751/751 - 35s - loss: 1.7475 - accuracy: 0.4559
dev acc=43.85%
Epoch 5/10000
751/751 - 35s - loss: 1.6909 - accuracy: 0.4715
dev acc=44.10%
Epoch 6/10000
751/751 - 35s - loss: 1.7013 - accuracy: 0.4626
dev acc=45.99%
test acc=45.17%
Epoch 7/10000
751/751 - 35s - loss: 1.6452 - accuracy: 0.4814
dev acc=45.56%
Epoch 8/10000
751/751 - 35s - loss: 1.6017 - accuracy: 0.4966
dev acc=45.60%
Epoch 9/10000
751/751 - 35s - loss: 1.5911 - accuracy: 0.4976
dev acc=46.95%
test acc=46.63%
Epoch 10/10000
751/751 - 35s - loss: 1.5858 - accuracy: 0.4976
dev acc=46.80%
Epoch 11/10000
751/751 - 35s - loss: 1.5615 - accuracy: 0.5066
dev acc=48.03%
test acc=46.72%
Epoch 12/10000
751/751 - 35s - loss: 1.5397 - accuracy: 0.5145
dev acc=47.58%
Epoch 13/10000
751/751 - 35s - loss: 1.4981 - accuracy: 0.5239
dev acc=47.26%
Epoch 14/10000
751/751 - 35s - loss: 1.4686 - accuracy: 0.5344
dev acc=47.86%
Epoch 15/10000
751/751 - 35s - loss: 1.4587 - accuracy: 0.5376
dev acc=47.43%
Epoch 16/10000
751/751 - 35s - loss: 1.4478 - accuracy: 0.5382
dev acc=47.99%
time used=750.7s
2022-05-12 17:54:33.095303: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
2.6.0
2.6.0
0.11.3
Namespace(batch_size=64, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_xlarge_google_zh_183k/albert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_xlarge_google_zh_183k/albert_config.json', dropout=0.5, epochs=10000, freeze=False, gpu='0', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='albert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/albert_zh/albert_xlarge_google_zh_183k/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_culture': 0, 'news_military': 1, 'news_entertainment': 2, 'news_agriculture': 3, 'news_finance': 4, 'news_story': 5, 'news_car': 6, 'news_stock': 7, 'news_travel': 8, 'news_world': 9, 'news_house': 10, 'news_game': 11, 'news_edu': 12, 'news_tech': 13, 'news_sports': 14}
index_labels_dict={0: 'news_culture', 1: 'news_military', 2: 'news_entertainment', 3: 'news_agriculture', 4: 'news_finance', 5: 'news_story', 6: 'news_car', 7: 'news_stock', 8: 'news_travel', 9: 'news_world', 10: 'news_house', 11: 'news_game', 12: 'news_edu', 13: 'news_tech', 14: 'news_sports'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-12 17:54:41.467183: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-12 17:54:42.300287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20998 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:02:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 2048)   43270144    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 2048)   4096        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 2048)   0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 2048)   1048576     Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 2048)   4096        Embedding-Position[0][0]         
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 2048)   16785408    Embedding-Norm[0][0]             
                                                                 Embedding-Norm[0][0]             
                                                                 Embedding-Norm[0][0]             
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-FeedForward-Norm[22][
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 2048)   0           Embedding-Norm[0][0]             
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[0][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[1][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[2][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[3][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[4][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[5][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[6][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[7][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[8][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[9][0
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[10][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[11][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[12][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[13][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[14][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[15][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[16][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[17][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[18][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[19][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[20][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[21][
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward-Norm[22][
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-MultiHeadSelfAttent (None, None, 2048)   4096        Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward (FeedFo (None, None, 2048)   33564672    Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-MultiHeadSelfAttentio
__________________________________________________________________________________________________
Transformer-FeedForward-Add (Ad (None, None, 2048)   0           Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[0][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[1][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[2][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[3][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[4][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[5][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[6][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[7][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[8][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[9][0]    
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[10][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[11][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[12][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[13][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[14][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[15][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[16][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[17][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[18][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[19][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[20][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[21][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[22][0]   
                                                                 Transformer-MultiHeadSelfAttentio
                                                                 Transformer-FeedForward[23][0]   
__________________________________________________________________________________________________
Transformer-FeedForward-Norm (L (None, None, 2048)   4096        Transformer-FeedForward-Add[0][0]
                                                                 Transformer-FeedForward-Add[1][0]
                                                                 Transformer-FeedForward-Add[2][0]
                                                                 Transformer-FeedForward-Add[3][0]
                                                                 Transformer-FeedForward-Add[4][0]
                                                                 Transformer-FeedForward-Add[5][0]
                                                                 Transformer-FeedForward-Add[6][0]
                                                                 Transformer-FeedForward-Add[7][0]
                                                                 Transformer-FeedForward-Add[8][0]
                                                                 Transformer-FeedForward-Add[9][0]
                                                                 Transformer-FeedForward-Add[10][0
                                                                 Transformer-FeedForward-Add[11][0
                                                                 Transformer-FeedForward-Add[12][0
                                                                 Transformer-FeedForward-Add[13][0
                                                                 Transformer-FeedForward-Add[14][0
                                                                 Transformer-FeedForward-Add[15][0
                                                                 Transformer-FeedForward-Add[16][0
                                                                 Transformer-FeedForward-Add[17][0
                                                                 Transformer-FeedForward-Add[18][0
                                                                 Transformer-FeedForward-Add[19][0
                                                                 Transformer-FeedForward-Add[20][0
                                                                 Transformer-FeedForward-Add[21][0
                                                                 Transformer-FeedForward-Add[22][0
                                                                 Transformer-FeedForward-Add[23][0
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 2048)         0           Transformer-FeedForward-Norm[23][
__________________________________________________________________________________________________
dropout (Dropout)               (None, 2048)         0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           30735       dropout[0][0]                    
==================================================================================================
Total params: 94,715,919
Trainable params: 94,715,919
Non-trainable params: 0
__________________________________________________________________________________________________
2022-05-12 17:54:48.061521: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
2022-05-12 17:55:45.720382: W tensorflow/core/common_runtime/bfc_allocator.cc:457] Allocator (GPU_0_bfc) ran out of memory trying to allocate 98.00MiB (rounded to 102760448)requested by op model_1/Transformer-FeedForward/dense/add_47
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. 
Current allocation summary follows.
Current allocation summary follows.
2022-05-12 17:55:45.720545: I tensorflow/core/common_runtime/bfc_allocator.cc:1004] BFCAllocator dump for GPU_0_bfc
2022-05-12 17:55:45.720599: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (256): 	Total Chunks: 395, Chunks in use: 393. 98.8KiB allocated for chunks. 98.2KiB in use in bin. 1.9KiB client-requested in use in bin.
2022-05-12 17:55:45.720619: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (512): 	Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.
2022-05-12 17:55:45.720639: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (1024): 	Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.
2022-05-12 17:55:45.720660: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (2048): 	Total Chunks: 48, Chunks in use: 48. 156.5KiB allocated for chunks. 156.5KiB in use in bin. 147.2KiB client-requested in use in bin.
2022-05-12 17:55:45.720678: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (4096): 	Total Chunks: 2, Chunks in use: 2. 9.0KiB allocated for chunks. 9.0KiB in use in bin. 6.1KiB client-requested in use in bin.
2022-05-12 17:55:45.720697: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (8192): 	Total Chunks: 125, Chunks in use: 125. 1.30MiB allocated for chunks. 1.30MiB in use in bin. 1.27MiB client-requested in use in bin.
2022-05-12 17:55:45.720718: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (16384): 	Total Chunks: 7, Chunks in use: 7. 123.2KiB allocated for chunks. 123.2KiB in use in bin. 97.0KiB client-requested in use in bin.
2022-05-12 17:55:45.720737: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (32768): 	Total Chunks: 5, Chunks in use: 5. 160.0KiB allocated for chunks. 160.0KiB in use in bin. 160.0KiB client-requested in use in bin.
2022-05-12 17:55:45.720756: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (65536): 	Total Chunks: 3, Chunks in use: 3. 360.0KiB allocated for chunks. 360.0KiB in use in bin. 360.0KiB client-requested in use in bin.
2022-05-12 17:55:45.720774: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (131072): 	Total Chunks: 2, Chunks in use: 2. 331.0KiB allocated for chunks. 331.0KiB in use in bin. 240.0KiB client-requested in use in bin.
2022-05-12 17:55:45.720792: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (262144): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-12 17:55:45.720815: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (524288): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-12 17:55:45.720833: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (1048576): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-12 17:55:45.720849: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (2097152): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-12 17:55:45.720868: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (4194304): 	Total Chunks: 5, Chunks in use: 5. 20.21MiB allocated for chunks. 20.21MiB in use in bin. 20.00MiB client-requested in use in bin.
2022-05-12 17:55:45.720885: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (8388608): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-12 17:55:45.720903: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (16777216): 	Total Chunks: 329, Chunks in use: 329. 7.72GiB allocated for chunks. 7.72GiB in use in bin. 7.57GiB client-requested in use in bin.
2022-05-12 17:55:45.720923: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (33554432): 	Total Chunks: 3, Chunks in use: 3. 130.12MiB allocated for chunks. 130.12MiB in use in bin. 73.50MiB client-requested in use in bin.
2022-05-12 17:55:45.720943: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (67108864): 	Total Chunks: 126, Chunks in use: 126. 11.83GiB allocated for chunks. 11.83GiB in use in bin. 11.73GiB client-requested in use in bin.
2022-05-12 17:55:45.720963: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (134217728): 	Total Chunks: 5, Chunks in use: 5. 827.04MiB allocated for chunks. 827.04MiB in use in bin. 691.19MiB client-requested in use in bin.
2022-05-12 17:55:45.720980: I tensorflow/core/common_runtime/bfc_allocator.cc:1011] Bin (268435456): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-12 17:55:45.720997: I tensorflow/core/common_runtime/bfc_allocator.cc:1027] Bin for 98.00MiB was 64.00MiB, Chunk State: 
2022-05-12 17:55:45.721012: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Next region of size 22018981888
2022-05-12 17:55:45.721031: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2000000 of size 1280 next 1
2022-05-12 17:55:45.721046: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2000500 of size 256 next 2
2022-05-12 17:55:45.721059: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2000600 of size 256 next 3
2022-05-12 17:55:45.721072: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2000700 of size 256 next 4
2022-05-12 17:55:45.721085: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2000800 of size 8192 next 11
2022-05-12 17:55:45.721099: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2002800 of size 256 next 12
2022-05-12 17:55:45.721112: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2002900 of size 8192 next 305
2022-05-12 17:55:45.721125: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2004900 of size 256 next 969
2022-05-12 17:55:45.721156: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2004a00 of size 8192 next 561
2022-05-12 17:55:45.721171: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2006a00 of size 256 next 564
2022-05-12 17:55:45.721183: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2006b00 of size 256 next 977
2022-05-12 17:55:45.721196: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2006c00 of size 256 next 857
2022-05-12 17:55:45.721214: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2006d00 of size 256 next 443
2022-05-12 17:55:45.721227: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2006e00 of size 256 next 431
2022-05-12 17:55:45.721240: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2006f00 of size 256 next 708
2022-05-12 17:55:45.721252: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2007000 of size 256 next 900
2022-05-12 17:55:45.721265: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2007100 of size 256 next 941
2022-05-12 17:55:45.721277: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2007200 of size 8192 next 465
2022-05-12 17:55:45.721290: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2009200 of size 256 next 300
2022-05-12 17:55:45.721303: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2009300 of size 8192 next 383
2022-05-12 17:55:45.721315: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a200b300 of size 256 next 267
2022-05-12 17:55:45.721328: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a200b400 of size 256 next 425
2022-05-12 17:55:45.721341: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a200b500 of size 256 next 354
2022-05-12 17:55:45.721353: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a200b600 of size 256 next 730
2022-05-12 17:55:45.721366: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a200b700 of size 256 next 764
2022-05-12 17:55:45.721379: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a200b800 of size 13056 next 667
2022-05-12 17:55:45.721392: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a200eb00 of size 8192 next 294
2022-05-12 17:55:45.721406: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2010b00 of size 12544 next 828
2022-05-12 17:55:45.721420: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2013c00 of size 19456 next 28
2022-05-12 17:55:45.721434: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2018800 of size 256 next 21
2022-05-12 17:55:45.721446: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2018900 of size 256 next 34
2022-05-12 17:55:45.721459: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2018a00 of size 256 next 35
2022-05-12 17:55:45.721472: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2018b00 of size 256 next 36
2022-05-12 17:55:45.721484: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2018c00 of size 256 next 37
2022-05-12 17:55:45.721497: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2018d00 of size 256 next 38
2022-05-12 17:55:45.721509: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2018e00 of size 256 next 39
2022-05-12 17:55:45.721522: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2018f00 of size 256 next 40
2022-05-12 17:55:45.721535: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2019000 of size 3328 next 384
2022-05-12 17:55:45.721548: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2019d00 of size 256 next 609
2022-05-12 17:55:45.721561: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2019e00 of size 256 next 1004
2022-05-12 17:55:45.721574: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2019f00 of size 256 next 484
2022-05-12 17:55:45.721587: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201a000 of size 4864 next 1001
2022-05-12 17:55:45.721601: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201b300 of size 3328 next 410
2022-05-12 17:55:45.721613: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c000 of size 256 next 27
2022-05-12 17:55:45.721626: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c100 of size 256 next 14
2022-05-12 17:55:45.721643: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c200 of size 256 next 605
2022-05-12 17:55:45.721656: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c300 of size 256 next 593
2022-05-12 17:55:45.721669: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c400 of size 256 next 632
2022-05-12 17:55:45.721682: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c500 of size 256 next 419
2022-05-12 17:55:45.721694: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c600 of size 256 next 397
2022-05-12 17:55:45.721707: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c700 of size 256 next 743
2022-05-12 17:55:45.721720: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c800 of size 256 next 868
2022-05-12 17:55:45.721732: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201c900 of size 256 next 710
2022-05-12 17:55:45.721745: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201ca00 of size 256 next 266
2022-05-12 17:55:45.721757: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201cb00 of size 256 next 442
2022-05-12 17:55:45.721770: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201cc00 of size 256 next 798
2022-05-12 17:55:45.721782: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201cd00 of size 256 next 394
2022-05-12 17:55:45.721795: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201ce00 of size 256 next 497
2022-05-12 17:55:45.721807: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201cf00 of size 256 next 610
2022-05-12 17:55:45.721820: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d000 of size 256 next 858
2022-05-12 17:55:45.721832: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d100 of size 256 next 516
2022-05-12 17:55:45.721845: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d200 of size 256 next 939
2022-05-12 17:55:45.721858: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d300 of size 256 next 480
2022-05-12 17:55:45.721870: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d400 of size 256 next 547
2022-05-12 17:55:45.721883: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d500 of size 256 next 831
2022-05-12 17:55:45.721895: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d600 of size 256 next 638
2022-05-12 17:55:45.721908: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d700 of size 256 next 762
2022-05-12 17:55:45.721920: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d800 of size 256 next 660
2022-05-12 17:55:45.721933: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201d900 of size 256 next 735
2022-05-12 17:55:45.721946: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201da00 of size 3840 next 522
2022-05-12 17:55:45.721960: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201e900 of size 512 next 373
2022-05-12 17:55:45.721973: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201eb00 of size 256 next 920
2022-05-12 17:55:45.721986: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201ec00 of size 256 next 298
2022-05-12 17:55:45.721998: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201ed00 of size 256 next 829
2022-05-12 17:55:45.722011: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201ee00 of size 256 next 815
2022-05-12 17:55:45.722024: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a201ef00 of size 4352 next 68
2022-05-12 17:55:45.722038: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2020000 of size 18176 next 29
2022-05-12 17:55:45.722055: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2024700 of size 256 next 30
2022-05-12 17:55:45.722068: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a2024800 of size 67108864 next 355
2022-05-12 17:55:45.722082: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5a6024800 of size 67108864 next 374
2022-05-12 17:55:45.722095: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5aa024800 of size 25690112 next 531
2022-05-12 17:55:45.722109: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ab8a4800 of size 49799936 next 51
2022-05-12 17:55:45.722122: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae822b00 of size 8448 next 676
2022-05-12 17:55:45.722142: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae824c00 of size 256 next 701
2022-05-12 17:55:45.722156: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae824d00 of size 256 next 712
2022-05-12 17:55:45.722169: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae824e00 of size 256 next 421
2022-05-12 17:55:45.722182: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae824f00 of size 9216 next 428
2022-05-12 17:55:45.722195: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae827300 of size 12544 next 474
2022-05-12 17:55:45.722208: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae82a400 of size 256 next 717
2022-05-12 17:55:45.722221: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae82a500 of size 256 next 627
2022-05-12 17:55:45.722234: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae82a600 of size 3328 next 680
2022-05-12 17:55:45.722246: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae82b300 of size 256 next 362
2022-05-12 17:55:45.722259: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae82b400 of size 256 next 755
2022-05-12 17:55:45.722272: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae82b500 of size 14080 next 350
2022-05-12 17:55:45.722285: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae82ec00 of size 8192 next 387
2022-05-12 17:55:45.722298: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae830c00 of size 8192 next 570
2022-05-12 17:55:45.722311: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae832c00 of size 8192 next 817
2022-05-12 17:55:45.722324: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae834c00 of size 8192 next 975
2022-05-12 17:55:45.722337: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae836c00 of size 256 next 356
2022-05-12 17:55:45.722350: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae836d00 of size 256 next 640
2022-05-12 17:55:45.722363: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae836e00 of size 256 next 644
2022-05-12 17:55:45.722376: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae836f00 of size 14592 next 405
2022-05-12 17:55:45.722389: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae83a800 of size 32768 next 1065
2022-05-12 17:55:45.722403: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae842800 of size 8192 next 794
2022-05-12 17:55:45.722416: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae844800 of size 152832 next 633
2022-05-12 17:55:45.722429: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae869d00 of size 256 next 317
2022-05-12 17:55:45.722443: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae869e00 of size 17152 next 23
2022-05-12 17:55:45.722456: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ae86e100 of size 16777216 next 440
2022-05-12 17:55:45.722470: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5af86e100 of size 16789760 next 277
2022-05-12 17:55:45.722488: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b0871200 of size 30974464 next 424
2022-05-12 17:55:45.722502: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b25fb400 of size 16777216 next 641
2022-05-12 17:55:45.722515: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b35fb400 of size 16777216 next 734
2022-05-12 17:55:45.722528: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b45fb400 of size 16777216 next 45
2022-05-12 17:55:45.722541: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b55fb400 of size 4194304 next 844
2022-05-12 17:55:45.722556: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b59fb400 of size 29370624 next 867
2022-05-12 17:55:45.722569: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b75fdd00 of size 4317184 next 342
2022-05-12 17:55:45.722583: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a1bd00 of size 8192 next 416
2022-05-12 17:55:45.722596: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a1dd00 of size 16384 next 459
2022-05-12 17:55:45.722610: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a21d00 of size 8192 next 318
2022-05-12 17:55:45.722623: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a23d00 of size 8192 next 513
2022-05-12 17:55:45.722635: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a25d00 of size 8192 next 308
2022-05-12 17:55:45.722648: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a27d00 of size 8704 next 540
2022-05-12 17:55:45.722662: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a29f00 of size 122880 next 995
2022-05-12 17:55:45.722675: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a47f00 of size 122880 next 283
2022-05-12 17:55:45.722688: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a65f00 of size 32768 next 811
2022-05-12 17:55:45.722701: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a6df00 of size 122880 next 937
2022-05-12 17:55:45.722714: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a8bf00 of size 8192 next 281
2022-05-12 17:55:45.722727: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a8df00 of size 8192 next 18
2022-05-12 17:55:45.722739: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a8ff00 of size 8192 next 833
2022-05-12 17:55:45.722752: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a91f00 of size 8192 next 452
2022-05-12 17:55:45.722765: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a93f00 of size 32768 next 646
2022-05-12 17:55:45.722777: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a9bf00 of size 8192 next 485
2022-05-12 17:55:45.722790: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7a9df00 of size 32768 next 999
2022-05-12 17:55:45.722803: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7aa5f00 of size 256 next 888
2022-05-12 17:55:45.722816: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7aa6000 of size 256 next 1048
2022-05-12 17:55:45.722829: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7aa6100 of size 16384 next 869
2022-05-12 17:55:45.722842: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7aaa100 of size 12544 next 980
2022-05-12 17:55:45.722854: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7aad200 of size 12544 next 607
2022-05-12 17:55:45.722867: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ab0300 of size 12544 next 727
2022-05-12 17:55:45.722880: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ab3400 of size 12544 next 336
2022-05-12 17:55:45.722896: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ab6500 of size 12544 next 613
2022-05-12 17:55:45.722909: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ab9600 of size 12544 next 796
2022-05-12 17:55:45.722922: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7abc700 of size 12544 next 879
2022-05-12 17:55:45.722935: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7abf800 of size 12544 next 1055
2022-05-12 17:55:45.722947: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ac2900 of size 12544 next 961
2022-05-12 17:55:45.722960: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ac5a00 of size 12544 next 656
2022-05-12 17:55:45.722973: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ac8b00 of size 12544 next 846
2022-05-12 17:55:45.722985: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7acbc00 of size 12544 next 335
2022-05-12 17:55:45.722998: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7aced00 of size 12544 next 346
2022-05-12 17:55:45.723011: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ad1e00 of size 12544 next 20
2022-05-12 17:55:45.723023: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ad4f00 of size 12544 next 751
2022-05-12 17:55:45.723036: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ad8000 of size 12544 next 909
2022-05-12 17:55:45.723049: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7adb100 of size 12544 next 768
2022-05-12 17:55:45.723061: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ade200 of size 12544 next 434
2022-05-12 17:55:45.723074: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ae1300 of size 12544 next 771
2022-05-12 17:55:45.723086: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ae4400 of size 12544 next 814
2022-05-12 17:55:45.723099: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7ae7500 of size 12544 next 573
2022-05-12 17:55:45.723112: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7aea600 of size 12544 next 895
2022-05-12 17:55:45.723124: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7aed700 of size 12544 next 683
2022-05-12 17:55:45.723144: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7af0800 of size 12544 next 429
2022-05-12 17:55:45.723157: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7af3900 of size 12544 next 927
2022-05-12 17:55:45.723170: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7af6a00 of size 16384 next 733
2022-05-12 17:55:45.723184: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5b7afaa00 of size 74461952 next 875
2022-05-12 17:55:45.723197: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5bc1fdd00 of size 67108864 next 327
2022-05-12 17:55:45.723209: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5c01fdd00 of size 16777216 next 264
2022-05-12 17:55:45.723222: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5c11fdd00 of size 16777216 next 883
2022-05-12 17:55:45.723235: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5c21fdd00 of size 16777216 next 699
2022-05-12 17:55:45.723247: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5c31fdd00 of size 16777216 next 732
2022-05-12 17:55:45.723260: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5c41fdd00 of size 16777216 next 322
2022-05-12 17:55:45.723273: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5c51fdd00 of size 16777216 next 1013
2022-05-12 17:55:45.723286: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5c61fdd00 of size 28377088 next 759
2022-05-12 17:55:45.723300: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5c7d0dd00 of size 67108864 next 756
2022-05-12 17:55:45.723317: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5cbd0dd00 of size 98566144 next 399
2022-05-12 17:55:45.723330: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5d1b0dd00 of size 16777216 next 351
2022-05-12 17:55:45.723343: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5d2b0dd00 of size 17825792 next 82
2022-05-12 17:55:45.723356: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5d3c0dd00 of size 25690112 next 515
2022-05-12 17:55:45.723369: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5d548dd00 of size 19668992 next 1061
2022-05-12 17:55:45.723382: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5d674fd00 of size 25690112 next 535
2022-05-12 17:55:45.723395: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5d7fcfd00 of size 25690112 next 642
2022-05-12 17:55:45.723408: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5d984fd00 of size 25690112 next 631
2022-05-12 17:55:45.723420: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5db0cfd00 of size 25690112 next 67
2022-05-12 17:55:45.723434: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5dc94fd00 of size 42262528 next 477
2022-05-12 17:55:45.723447: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5df19dd00 of size 67108864 next 590
2022-05-12 17:55:45.723460: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e319dd00 of size 78507008 next 83
2022-05-12 17:55:45.723474: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7c900 of size 256 next 84
2022-05-12 17:55:45.723486: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7ca00 of size 256 next 85
2022-05-12 17:55:45.723499: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7cb00 of size 256 next 86
2022-05-12 17:55:45.723512: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7cc00 of size 256 next 87
2022-05-12 17:55:45.723524: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7cd00 of size 256 next 88
2022-05-12 17:55:45.723537: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7ce00 of size 256 next 89
2022-05-12 17:55:45.723550: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7cf00 of size 256 next 90
2022-05-12 17:55:45.723562: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d000 of size 256 next 91
2022-05-12 17:55:45.723575: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d100 of size 256 next 92
2022-05-12 17:55:45.723587: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d200 of size 256 next 93
2022-05-12 17:55:45.723600: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d300 of size 256 next 94
2022-05-12 17:55:45.723612: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d400 of size 256 next 95
2022-05-12 17:55:45.723625: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d500 of size 256 next 96
2022-05-12 17:55:45.723638: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d600 of size 256 next 97
2022-05-12 17:55:45.723650: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d700 of size 256 next 98
2022-05-12 17:55:45.723663: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d800 of size 256 next 99
2022-05-12 17:55:45.723676: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7d900 of size 256 next 100
2022-05-12 17:55:45.723688: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7da00 of size 256 next 101
2022-05-12 17:55:45.723701: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7db00 of size 256 next 102
2022-05-12 17:55:45.723714: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7dc00 of size 256 next 103
2022-05-12 17:55:45.723730: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7dd00 of size 256 next 104
2022-05-12 17:55:45.723743: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7de00 of size 256 next 105
2022-05-12 17:55:45.723756: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7df00 of size 256 next 106
2022-05-12 17:55:45.723769: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e000 of size 256 next 107
2022-05-12 17:55:45.723781: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e100 of size 256 next 108
2022-05-12 17:55:45.723794: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e200 of size 256 next 109
2022-05-12 17:55:45.723807: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e300 of size 256 next 110
2022-05-12 17:55:45.723819: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e400 of size 256 next 111
2022-05-12 17:55:45.723832: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e500 of size 256 next 112
2022-05-12 17:55:45.723845: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e600 of size 256 next 113
2022-05-12 17:55:45.723857: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e700 of size 256 next 114
2022-05-12 17:55:45.723870: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e800 of size 256 next 115
2022-05-12 17:55:45.723882: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7e900 of size 256 next 116
2022-05-12 17:55:45.723895: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7ea00 of size 256 next 117
2022-05-12 17:55:45.723907: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7eb00 of size 256 next 118
2022-05-12 17:55:45.723920: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7ec00 of size 256 next 119
2022-05-12 17:55:45.723933: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7ed00 of size 256 next 120
2022-05-12 17:55:45.723945: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7ee00 of size 256 next 121
2022-05-12 17:55:45.723958: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7ef00 of size 256 next 122
2022-05-12 17:55:45.723970: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f000 of size 256 next 123
2022-05-12 17:55:45.723983: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f100 of size 256 next 124
2022-05-12 17:55:45.723995: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f200 of size 256 next 125
2022-05-12 17:55:45.724008: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f300 of size 256 next 126
2022-05-12 17:55:45.724020: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f400 of size 256 next 127
2022-05-12 17:55:45.724033: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f500 of size 256 next 128
2022-05-12 17:55:45.724046: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f600 of size 256 next 129
2022-05-12 17:55:45.724058: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f700 of size 256 next 130
2022-05-12 17:55:45.724071: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f800 of size 256 next 131
2022-05-12 17:55:45.724083: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7f900 of size 256 next 132
2022-05-12 17:55:45.724096: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7fa00 of size 256 next 133
2022-05-12 17:55:45.724108: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7fb00 of size 256 next 134
2022-05-12 17:55:45.724121: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7fc00 of size 256 next 135
2022-05-12 17:55:45.724145: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7fd00 of size 256 next 136
2022-05-12 17:55:45.724160: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7fe00 of size 256 next 137
2022-05-12 17:55:45.724172: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c7ff00 of size 256 next 138
2022-05-12 17:55:45.724185: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80000 of size 256 next 139
2022-05-12 17:55:45.724198: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80100 of size 256 next 140
2022-05-12 17:55:45.724211: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80200 of size 256 next 141
2022-05-12 17:55:45.724223: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80300 of size 256 next 142
2022-05-12 17:55:45.724236: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80400 of size 256 next 143
2022-05-12 17:55:45.724248: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80500 of size 256 next 144
2022-05-12 17:55:45.724261: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80600 of size 256 next 145
2022-05-12 17:55:45.724274: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80700 of size 256 next 146
2022-05-12 17:55:45.724286: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80800 of size 256 next 147
2022-05-12 17:55:45.724299: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80900 of size 256 next 148
2022-05-12 17:55:45.724312: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80a00 of size 256 next 149
2022-05-12 17:55:45.724324: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80b00 of size 256 next 150
2022-05-12 17:55:45.724337: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80c00 of size 256 next 151
2022-05-12 17:55:45.724349: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80d00 of size 256 next 152
2022-05-12 17:55:45.724362: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80e00 of size 256 next 153
2022-05-12 17:55:45.724374: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c80f00 of size 256 next 154
2022-05-12 17:55:45.724387: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81000 of size 256 next 155
2022-05-12 17:55:45.724400: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81100 of size 256 next 156
2022-05-12 17:55:45.724412: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81200 of size 256 next 157
2022-05-12 17:55:45.724425: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81300 of size 256 next 158
2022-05-12 17:55:45.724437: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81400 of size 256 next 159
2022-05-12 17:55:45.724450: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81500 of size 256 next 160
2022-05-12 17:55:45.724462: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81600 of size 256 next 161
2022-05-12 17:55:45.724475: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81700 of size 256 next 162
2022-05-12 17:55:45.724487: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81800 of size 256 next 163
2022-05-12 17:55:45.724500: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81900 of size 256 next 164
2022-05-12 17:55:45.724512: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81a00 of size 256 next 165
2022-05-12 17:55:45.724525: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81b00 of size 256 next 166
2022-05-12 17:55:45.724538: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81c00 of size 256 next 167
2022-05-12 17:55:45.724554: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81d00 of size 256 next 168
2022-05-12 17:55:45.724567: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81e00 of size 256 next 169
2022-05-12 17:55:45.724580: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c81f00 of size 256 next 170
2022-05-12 17:55:45.724592: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82000 of size 256 next 171
2022-05-12 17:55:45.724605: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82100 of size 256 next 172
2022-05-12 17:55:45.724617: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82200 of size 256 next 173
2022-05-12 17:55:45.724630: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82300 of size 256 next 174
2022-05-12 17:55:45.724643: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82400 of size 256 next 175
2022-05-12 17:55:45.724655: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82500 of size 256 next 176
2022-05-12 17:55:45.724668: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82600 of size 256 next 177
2022-05-12 17:55:45.724681: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82700 of size 256 next 178
2022-05-12 17:55:45.724693: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82800 of size 256 next 179
2022-05-12 17:55:45.724706: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82900 of size 256 next 180
2022-05-12 17:55:45.724719: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82a00 of size 256 next 181
2022-05-12 17:55:45.724731: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82b00 of size 256 next 182
2022-05-12 17:55:45.724744: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82c00 of size 256 next 183
2022-05-12 17:55:45.724756: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82d00 of size 256 next 184
2022-05-12 17:55:45.724769: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82e00 of size 256 next 185
2022-05-12 17:55:45.724782: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c82f00 of size 256 next 186
2022-05-12 17:55:45.724794: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83000 of size 256 next 187
2022-05-12 17:55:45.724807: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83100 of size 256 next 188
2022-05-12 17:55:45.724819: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83200 of size 256 next 189
2022-05-12 17:55:45.724832: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83300 of size 256 next 190
2022-05-12 17:55:45.724845: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83400 of size 256 next 191
2022-05-12 17:55:45.724857: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83500 of size 256 next 192
2022-05-12 17:55:45.724870: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83600 of size 256 next 193
2022-05-12 17:55:45.724883: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83700 of size 256 next 194
2022-05-12 17:55:45.724896: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83800 of size 256 next 195
2022-05-12 17:55:45.724908: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83900 of size 256 next 196
2022-05-12 17:55:45.724921: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83a00 of size 256 next 197
2022-05-12 17:55:45.724933: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83b00 of size 256 next 198
2022-05-12 17:55:45.724946: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83c00 of size 256 next 199
2022-05-12 17:55:45.724959: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83d00 of size 256 next 200
2022-05-12 17:55:45.724974: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83e00 of size 256 next 201
2022-05-12 17:55:45.724987: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c83f00 of size 256 next 202
2022-05-12 17:55:45.725000: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84000 of size 256 next 203
2022-05-12 17:55:45.725013: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84100 of size 256 next 204
2022-05-12 17:55:45.725025: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84200 of size 256 next 205
2022-05-12 17:55:45.725038: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84300 of size 256 next 206
2022-05-12 17:55:45.725051: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84400 of size 256 next 207
2022-05-12 17:55:45.725063: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84500 of size 256 next 208
2022-05-12 17:55:45.725076: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84600 of size 256 next 209
2022-05-12 17:55:45.725089: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84700 of size 256 next 210
2022-05-12 17:55:45.725101: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84800 of size 256 next 211
2022-05-12 17:55:45.725114: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84900 of size 256 next 212
2022-05-12 17:55:45.725127: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84a00 of size 256 next 213
2022-05-12 17:55:45.725146: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84b00 of size 256 next 214
2022-05-12 17:55:45.725159: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84c00 of size 256 next 215
2022-05-12 17:55:45.725172: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84d00 of size 256 next 216
2022-05-12 17:55:45.725185: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84e00 of size 256 next 217
2022-05-12 17:55:45.725198: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c84f00 of size 256 next 218
2022-05-12 17:55:45.725210: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85000 of size 256 next 219
2022-05-12 17:55:45.725223: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85100 of size 256 next 220
2022-05-12 17:55:45.725236: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85200 of size 256 next 221
2022-05-12 17:55:45.725248: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85300 of size 256 next 222
2022-05-12 17:55:45.725261: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85400 of size 256 next 223
2022-05-12 17:55:45.725274: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85500 of size 256 next 224
2022-05-12 17:55:45.725286: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85600 of size 256 next 225
2022-05-12 17:55:45.725299: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85700 of size 256 next 226
2022-05-12 17:55:45.725312: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85800 of size 256 next 227
2022-05-12 17:55:45.725324: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85900 of size 256 next 228
2022-05-12 17:55:45.725337: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85a00 of size 256 next 229
2022-05-12 17:55:45.725350: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85b00 of size 256 next 230
2022-05-12 17:55:45.725362: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85c00 of size 256 next 231
2022-05-12 17:55:45.725375: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85d00 of size 256 next 232
2022-05-12 17:55:45.725392: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85e00 of size 256 next 233
2022-05-12 17:55:45.725405: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c85f00 of size 256 next 234
2022-05-12 17:55:45.725418: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86000 of size 256 next 235
2022-05-12 17:55:45.725430: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86100 of size 256 next 236
2022-05-12 17:55:45.725443: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86200 of size 256 next 237
2022-05-12 17:55:45.725456: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86300 of size 256 next 238
2022-05-12 17:55:45.725468: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86400 of size 256 next 239
2022-05-12 17:55:45.725481: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86500 of size 256 next 240
2022-05-12 17:55:45.725494: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86600 of size 256 next 241
2022-05-12 17:55:45.725507: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86700 of size 256 next 242
2022-05-12 17:55:45.725519: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86800 of size 256 next 243
2022-05-12 17:55:45.725532: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86900 of size 256 next 244
2022-05-12 17:55:45.725545: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86a00 of size 256 next 245
2022-05-12 17:55:45.725557: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86b00 of size 256 next 246
2022-05-12 17:55:45.725570: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86c00 of size 256 next 247
2022-05-12 17:55:45.725583: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86d00 of size 256 next 248
2022-05-12 17:55:45.725596: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86e00 of size 256 next 249
2022-05-12 17:55:45.725608: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c86f00 of size 256 next 250
2022-05-12 17:55:45.725621: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87000 of size 256 next 251
2022-05-12 17:55:45.725634: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87100 of size 256 next 252
2022-05-12 17:55:45.725647: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87200 of size 256 next 253
2022-05-12 17:55:45.725659: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87300 of size 256 next 254
2022-05-12 17:55:45.725672: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87400 of size 256 next 255
2022-05-12 17:55:45.725685: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87500 of size 256 next 256
2022-05-12 17:55:45.725697: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87600 of size 256 next 257
2022-05-12 17:55:45.725710: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87700 of size 256 next 258
2022-05-12 17:55:45.725723: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87800 of size 256 next 259
2022-05-12 17:55:45.725736: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87900 of size 256 next 260
2022-05-12 17:55:45.725748: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87a00 of size 256 next 261
2022-05-12 17:55:45.725761: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87b00 of size 256 next 262
2022-05-12 17:55:45.725775: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e7c87c00 of size 4242432 next 287
2022-05-12 17:55:45.725788: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e8093800 of size 4194304 next 403
2022-05-12 17:55:45.725809: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e8493800 of size 4244736 next 349
2022-05-12 17:55:45.725824: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e889fd00 of size 8192 next 578
2022-05-12 17:55:45.725837: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a1d00 of size 8192 next 314
2022-05-12 17:55:45.725850: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a3d00 of size 256 next 924
2022-05-12 17:55:45.725863: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a3e00 of size 256 next 423
2022-05-12 17:55:45.725875: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a3f00 of size 256 next 650
2022-05-12 17:55:45.725888: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a4000 of size 256 next 407
2022-05-12 17:55:45.725901: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a4100 of size 256 next 1066
2022-05-12 17:55:45.725914: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a4200 of size 256 next 41
2022-05-12 17:55:45.725927: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a4300 of size 8192 next 347
2022-05-12 17:55:45.725940: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a6300 of size 8192 next 382
2022-05-12 17:55:45.725953: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a8300 of size 256 next 295
2022-05-12 17:55:45.725966: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88a8400 of size 8192 next 684
2022-05-12 17:55:45.725979: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88aa400 of size 8192 next 13
2022-05-12 17:55:45.725991: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88ac400 of size 8192 next 460
2022-05-12 17:55:45.726004: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88ae400 of size 8192 next 950
2022-05-12 17:55:45.726017: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b0400 of size 256 next 741
2022-05-12 17:55:45.726031: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b0500 of size 14336 next 688
2022-05-12 17:55:45.726044: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b3d00 of size 8448 next 576
2022-05-12 17:55:45.726057: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b5e00 of size 8192 next 979
2022-05-12 17:55:45.726070: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b7e00 of size 256 next 885
2022-05-12 17:55:45.726083: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b7f00 of size 256 next 601
2022-05-12 17:55:45.726096: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8000 of size 256 next 50
2022-05-12 17:55:45.726109: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8100 of size 256 next 661
2022-05-12 17:55:45.726122: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8200 of size 256 next 60
2022-05-12 17:55:45.726141: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8300 of size 256 next 412
2022-05-12 17:55:45.726155: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8400 of size 256 next 24
2022-05-12 17:55:45.726169: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8500 of size 256 next 968
2022-05-12 17:55:45.726182: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8600 of size 256 next 512
2022-05-12 17:55:45.726195: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8700 of size 256 next 559
2022-05-12 17:55:45.726208: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8800 of size 256 next 841
2022-05-12 17:55:45.726220: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8900 of size 256 next 293
2022-05-12 17:55:45.726238: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8a00 of size 256 next 674
2022-05-12 17:55:45.726251: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8b00 of size 256 next 395
2022-05-12 17:55:45.726264: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8c00 of size 256 next 279
2022-05-12 17:55:45.726276: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8d00 of size 256 next 320
2022-05-12 17:55:45.726289: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8e00 of size 256 next 353
2022-05-12 17:55:45.726302: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b8f00 of size 256 next 987
2022-05-12 17:55:45.726314: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b9000 of size 256 next 649
2022-05-12 17:55:45.726327: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88b9100 of size 8192 next 935
2022-05-12 17:55:45.726340: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bb100 of size 8192 next 954
2022-05-12 17:55:45.726353: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bd100 of size 256 next 621
2022-05-12 17:55:45.726366: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bd200 of size 8192 next 1062
2022-05-12 17:55:45.726379: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bf200 of size 256 next 978
2022-05-12 17:55:45.726391: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bf300 of size 256 next 329
2022-05-12 17:55:45.726404: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bf400 of size 256 next 76
2022-05-12 17:55:45.726417: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bf500 of size 256 next 488
2022-05-12 17:55:45.726429: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bf600 of size 256 next 413
2022-05-12 17:55:45.726442: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bf700 of size 256 next 963
2022-05-12 17:55:45.726454: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bf800 of size 256 next 803
2022-05-12 17:55:45.726467: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bf900 of size 256 next 518
2022-05-12 17:55:45.726480: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88bfa00 of size 8192 next 1053
2022-05-12 17:55:45.726493: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c1a00 of size 256 next 1057
2022-05-12 17:55:45.726506: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c1b00 of size 8192 next 307
2022-05-12 17:55:45.726518: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c3b00 of size 256 next 289
2022-05-12 17:55:45.726531: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c3c00 of size 256 next 882
2022-05-12 17:55:45.726544: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c3d00 of size 256 next 469
2022-05-12 17:55:45.726556: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c3e00 of size 256 next 1074
2022-05-12 17:55:45.726569: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c3f00 of size 256 next 628
2022-05-12 17:55:45.726582: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c4000 of size 12544 next 273
2022-05-12 17:55:45.726595: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c7100 of size 8192 next 534
2022-05-12 17:55:45.726608: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c9100 of size 256 next 592
2022-05-12 17:55:45.726620: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c9200 of size 256 next 903
2022-05-12 17:55:45.726633: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c9300 of size 256 next 10
2022-05-12 17:55:45.726649: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c9400 of size 256 next 558
2022-05-12 17:55:45.726662: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c9500 of size 256 next 946
2022-05-12 17:55:45.726675: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c9600 of size 256 next 639
2022-05-12 17:55:45.726688: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88c9700 of size 8192 next 634
2022-05-12 17:55:45.726701: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88cb700 of size 8192 next 448
2022-05-12 17:55:45.726714: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88cd700 of size 256 next 269
2022-05-12 17:55:45.726726: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88cd800 of size 8192 next 53
2022-05-12 17:55:45.726739: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88cf800 of size 8192 next 499
2022-05-12 17:55:45.726752: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88d1800 of size 8192 next 496
2022-05-12 17:55:45.726765: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88d3800 of size 8192 next 533
2022-05-12 17:55:45.726778: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88d5800 of size 256 next 887
2022-05-12 17:55:45.726790: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88d5900 of size 8192 next 532
2022-05-12 17:55:45.726803: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88d7900 of size 14336 next 500
2022-05-12 17:55:45.726817: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e88db100 of size 186112 next 746
2022-05-12 17:55:45.726830: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e8908800 of size 8192 next 79
2022-05-12 17:55:45.726842: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e890a800 of size 8192 next 933
2022-05-12 17:55:45.726855: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e890c800 of size 8192 next 783
2022-05-12 17:55:45.726868: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e890e800 of size 32768 next 970
2022-05-12 17:55:45.726881: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e8916800 of size 8192 next 446
2022-05-12 17:55:45.726894: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e8918800 of size 256 next 1021
2022-05-12 17:55:45.726907: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e8918900 of size 256 next 303
2022-05-12 17:55:45.726920: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5e8918a00 of size 25690112 next 555
2022-05-12 17:55:45.726933: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ea198a00 of size 25690112 next 574
2022-05-12 17:55:45.726945: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba18a00 of size 12544 next 339
2022-05-12 17:55:45.726958: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba1bb00 of size 12544 next 467
2022-05-12 17:55:45.726971: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba1ec00 of size 12544 next 309
2022-05-12 17:55:45.726984: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba21d00 of size 12544 next 637
2022-05-12 17:55:45.726996: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba24e00 of size 12544 next 972
2022-05-12 17:55:45.727009: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba27f00 of size 12544 next 1060
2022-05-12 17:55:45.727022: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba2b000 of size 12544 next 301
2022-05-12 17:55:45.727035: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba2e100 of size 12544 next 983
2022-05-12 17:55:45.727048: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba31200 of size 12544 next 672
2022-05-12 17:55:45.727064: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba34300 of size 12544 next 1027
2022-05-12 17:55:45.727078: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba37400 of size 12544 next 653
2022-05-12 17:55:45.727091: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba3a500 of size 12544 next 615
2022-05-12 17:55:45.727103: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba3d600 of size 12544 next 1052
2022-05-12 17:55:45.727116: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba40700 of size 12544 next 594
2022-05-12 17:55:45.727129: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba43800 of size 12544 next 33
2022-05-12 17:55:45.727148: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba46900 of size 12544 next 745
2022-05-12 17:55:45.727161: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba49a00 of size 12544 next 716
2022-05-12 17:55:45.727173: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba4cb00 of size 12544 next 889
2022-05-12 17:55:45.727186: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba4fc00 of size 12544 next 386
2022-05-12 17:55:45.727199: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba52d00 of size 12544 next 913
2022-05-12 17:55:45.727212: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba55e00 of size 12544 next 1067
2022-05-12 17:55:45.727225: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba58f00 of size 12544 next 944
2022-05-12 17:55:45.727238: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba5c000 of size 3328 next 840
2022-05-12 17:55:45.727251: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba5cd00 of size 256 next 337
2022-05-12 17:55:45.727264: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba5ce00 of size 256 next 894
2022-05-12 17:55:45.727277: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba5cf00 of size 3328 next 864
2022-05-12 17:55:45.727290: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba5dc00 of size 256 next 1073
2022-05-12 17:55:45.727303: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba5dd00 of size 256 next 719
2022-05-12 17:55:45.727316: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba5de00 of size 12544 next 392
2022-05-12 17:55:45.727329: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba60f00 of size 3328 next 917
2022-05-12 17:55:45.727342: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba61c00 of size 256 next 604
2022-05-12 17:55:45.727355: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba61d00 of size 256 next 893
2022-05-12 17:55:45.727367: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba61e00 of size 3328 next 862
2022-05-12 17:55:45.727380: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba62b00 of size 256 next 619
2022-05-12 17:55:45.727393: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba62c00 of size 256 next 502
2022-05-12 17:55:45.727406: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba62d00 of size 22272 next 471
2022-05-12 17:55:45.727420: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eba68400 of size 25690112 next 566
2022-05-12 17:55:45.727433: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ed2e8400 of size 25690112 next 17
2022-05-12 17:55:45.727446: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5eeb68400 of size 25690112 next 603
2022-05-12 17:55:45.727460: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5f03e8400 of size 44375040 next 998
2022-05-12 17:55:45.727474: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5f2e3a000 of size 176132096 next 439
2022-05-12 17:55:45.727491: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5fd633000 of size 16777216 next 976
2022-05-12 17:55:45.727505: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5fe633000 of size 16777216 next 417
2022-05-12 17:55:45.727518: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa5ff633000 of size 173080576 next 706
2022-05-12 17:55:45.727532: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa609b43000 of size 19398656 next 505
2022-05-12 17:55:45.727545: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa60adc3000 of size 77594624 next 718
2022-05-12 17:55:45.727558: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa60f7c3000 of size 173080576 next 982
2022-05-12 17:55:45.727572: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa619cd3000 of size 102760448 next 586
2022-05-12 17:55:45.727585: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa61fed3000 of size 102760448 next 567
2022-05-12 17:55:45.727598: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6260d3000 of size 102760448 next 608
2022-05-12 17:55:45.727612: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa62c2d3000 of size 151389184 next 489
2022-05-12 17:55:45.727625: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa635333400 of size 20447232 next 554
2022-05-12 17:55:45.727639: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6366b3400 of size 81788928 next 78
2022-05-12 17:55:45.727652: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa63b4b3400 of size 102760448 next 943
2022-05-12 17:55:45.727665: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6416b3400 of size 25690112 next 1041
2022-05-12 17:55:45.727678: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa642f33400 of size 25690112 next 957
2022-05-12 17:55:45.727691: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6447b3400 of size 3328 next 993
2022-05-12 17:55:45.727704: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6447b4100 of size 256 next 537
2022-05-12 17:55:45.727717: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6447b4200 of size 256 next 668
2022-05-12 17:55:45.727731: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6447b4300 of size 25686272 next 725
2022-05-12 17:55:45.727744: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa646033400 of size 12544 next 595
2022-05-12 17:55:45.727758: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa646036500 of size 25690112 next 973
2022-05-12 17:55:45.727770: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6478b6500 of size 25690112 next 681
2022-05-12 17:55:45.727783: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa649136500 of size 25690112 next 311
2022-05-12 17:55:45.727796: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa64a9b6500 of size 25690112 next 918
2022-05-12 17:55:45.727809: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa64c236500 of size 25690112 next 453
2022-05-12 17:55:45.727822: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa64dab6500 of size 25690112 next 707
2022-05-12 17:55:45.727834: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa64f336500 of size 25690112 next 306
2022-05-12 17:55:45.727847: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa650bb6500 of size 25690112 next 663
2022-05-12 17:55:45.727860: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa652436500 of size 3328 next 391
2022-05-12 17:55:45.727873: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa652437200 of size 25690112 next 813
2022-05-12 17:55:45.727885: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa653cb7200 of size 25690112 next 546
2022-05-12 17:55:45.727903: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa655537200 of size 256 next 52
2022-05-12 17:55:45.727916: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa655537300 of size 256 next 398
2022-05-12 17:55:45.727929: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa655537400 of size 102760448 next 807
2022-05-12 17:55:45.727942: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa65b737400 of size 102760448 next 842
2022-05-12 17:55:45.727955: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa661937400 of size 102760448 next 451
2022-05-12 17:55:45.727967: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa667b37400 of size 102760448 next 310
2022-05-12 17:55:45.727980: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa66dd37400 of size 102760448 next 971
2022-05-12 17:55:45.727993: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa673f37400 of size 25690112 next 891
2022-05-12 17:55:45.728006: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6757b7400 of size 25690112 next 551
2022-05-12 17:55:45.728019: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa677037400 of size 3328 next 853
2022-05-12 17:55:45.728032: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa677038100 of size 256 next 364
2022-05-12 17:55:45.728045: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa677038200 of size 256 next 664
2022-05-12 17:55:45.728058: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa677038300 of size 25686272 next 1031
2022-05-12 17:55:45.728070: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6788b7400 of size 12544 next 636
2022-05-12 17:55:45.728083: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6788ba500 of size 25690112 next 825
2022-05-12 17:55:45.728096: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa67a13a500 of size 25690112 next 519
2022-05-12 17:55:45.728109: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa67b9ba500 of size 25690112 next 495
2022-05-12 17:55:45.728121: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa67d23a500 of size 25690112 next 284
2022-05-12 17:55:45.728139: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa67eaba500 of size 25690112 next 677
2022-05-12 17:55:45.728153: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa68033a500 of size 25690112 next 507
2022-05-12 17:55:45.728166: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa681bba500 of size 25690112 next 703
2022-05-12 17:55:45.728179: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa68343a500 of size 25690112 next 872
2022-05-12 17:55:45.728192: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa684cba500 of size 3328 next 1003
2022-05-12 17:55:45.728205: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa684cbb200 of size 25690112 next 992
2022-05-12 17:55:45.728217: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa68653b200 of size 25690112 next 569
2022-05-12 17:55:45.728230: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa687dbb200 of size 256 next 784
2022-05-12 17:55:45.728243: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa687dbb300 of size 256 next 777
2022-05-12 17:55:45.728256: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa687dbb400 of size 102760448 next 1024
2022-05-12 17:55:45.728269: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa68dfbb400 of size 102760448 next 702
2022-05-12 17:55:45.728282: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6941bb400 of size 102760448 next 598
2022-05-12 17:55:45.728295: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa69a3bb400 of size 102760448 next 990
2022-05-12 17:55:45.728312: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6a05bb400 of size 102760448 next 509
2022-05-12 17:55:45.728326: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6a67bb400 of size 25690112 next 908
2022-05-12 17:55:45.728338: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6a803b400 of size 25690112 next 503
2022-05-12 17:55:45.728351: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6a98bb400 of size 3328 next 369
2022-05-12 17:55:45.728364: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6a98bc100 of size 256 next 709
2022-05-12 17:55:45.728377: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6a98bc200 of size 256 next 1045
2022-05-12 17:55:45.728390: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6a98bc300 of size 25686272 next 280
2022-05-12 17:55:45.728403: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ab13b400 of size 12544 next 852
2022-05-12 17:55:45.728416: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ab13e500 of size 25690112 next 486
2022-05-12 17:55:45.728429: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ac9be500 of size 25690112 next 43
2022-05-12 17:55:45.728442: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ae23e500 of size 25690112 next 1014
2022-05-12 17:55:45.728454: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6afabe500 of size 25690112 next 851
2022-05-12 17:55:45.728467: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6b133e500 of size 25690112 next 70
2022-05-12 17:55:45.728480: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6b2bbe500 of size 25690112 next 696
2022-05-12 17:55:45.728493: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6b443e500 of size 25690112 next 544
2022-05-12 17:55:45.728505: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6b5cbe500 of size 25690112 next 517
2022-05-12 17:55:45.728518: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6b753e500 of size 3328 next 899
2022-05-12 17:55:45.728531: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6b753f200 of size 25690112 next 729
2022-05-12 17:55:45.728544: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6b8dbf200 of size 25690112 next 747
2022-05-12 17:55:45.728556: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ba63f200 of size 256 next 690
2022-05-12 17:55:45.728569: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ba63f300 of size 256 next 925
2022-05-12 17:55:45.728582: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ba63f400 of size 102760448 next 921
2022-05-12 17:55:45.728595: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6c083f400 of size 102760448 next 436
2022-05-12 17:55:45.728608: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6c6a3f400 of size 102760448 next 15
2022-05-12 17:55:45.728621: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ccc3f400 of size 102760448 next 721
2022-05-12 17:55:45.728634: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6d2e3f400 of size 102760448 next 1056
2022-05-12 17:55:45.728647: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6d903f400 of size 25690112 next 956
2022-05-12 17:55:45.728660: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6da8bf400 of size 25690112 next 744
2022-05-12 17:55:45.728673: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6dc13f400 of size 3328 next 878
2022-05-12 17:55:45.728686: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6dc140100 of size 256 next 538
2022-05-12 17:55:45.728698: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6dc140200 of size 256 next 651
2022-05-12 17:55:45.728711: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6dc140300 of size 25686272 next 797
2022-05-12 17:55:45.728728: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6dd9bf400 of size 12544 next 487
2022-05-12 17:55:45.728741: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6dd9c2500 of size 25690112 next 408
2022-05-12 17:55:45.728754: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6df242500 of size 25690112 next 662
2022-05-12 17:55:45.728767: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6e0ac2500 of size 25690112 next 984
2022-05-12 17:55:45.728780: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6e2342500 of size 25690112 next 912
2022-05-12 17:55:45.728792: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6e3bc2500 of size 25690112 next 695
2022-05-12 17:55:45.728805: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6e5442500 of size 25690112 next 494
2022-05-12 17:55:45.728817: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6e6cc2500 of size 25690112 next 652
2022-05-12 17:55:45.728830: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6e8542500 of size 25690112 next 1050
2022-05-12 17:55:45.728843: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6e9dc2500 of size 3328 next 562
2022-05-12 17:55:45.728856: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6e9dc3200 of size 25690112 next 1005
2022-05-12 17:55:45.728869: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6eb643200 of size 25690112 next 687
2022-05-12 17:55:45.728882: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ecec3200 of size 256 next 437
2022-05-12 17:55:45.728895: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ecec3300 of size 256 next 647
2022-05-12 17:55:45.728908: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ecec3400 of size 102760448 next 292
2022-05-12 17:55:45.728921: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6f30c3400 of size 102760448 next 529
2022-05-12 17:55:45.728933: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6f92c3400 of size 102760448 next 325
2022-05-12 17:55:45.728946: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa6ff4c3400 of size 102760448 next 521
2022-05-12 17:55:45.728959: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7056c3400 of size 102760448 next 1035
2022-05-12 17:55:45.728972: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa70b8c3400 of size 25690112 next 376
2022-05-12 17:55:45.728985: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa70d143400 of size 25690112 next 330
2022-05-12 17:55:45.728998: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa70e9c3400 of size 3328 next 582
2022-05-12 17:55:45.729011: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa70e9c4100 of size 256 next 577
2022-05-12 17:55:45.729023: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa70e9c4200 of size 256 next 711
2022-05-12 17:55:45.729036: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa70e9c4300 of size 25686272 next 758
2022-05-12 17:55:45.729049: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa710243400 of size 12544 next 830
2022-05-12 17:55:45.729062: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa710246500 of size 25690112 next 297
2022-05-12 17:55:45.729075: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa711ac6500 of size 25690112 next 61
2022-05-12 17:55:45.729088: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa713346500 of size 25690112 next 589
2022-05-12 17:55:45.729101: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa714bc6500 of size 25690112 next 74
2022-05-12 17:55:45.729114: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa716446500 of size 25690112 next 1072
2022-05-12 17:55:45.729137: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa717cc6500 of size 25690112 next 25
2022-05-12 17:55:45.729152: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa719546500 of size 25690112 next 304
2022-05-12 17:55:45.729165: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa71adc6500 of size 25690112 next 635
2022-05-12 17:55:45.729178: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa71c646500 of size 3328 next 276
2022-05-12 17:55:45.729190: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa71c647200 of size 25690112 next 826
2022-05-12 17:55:45.729203: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa71dec7200 of size 25690112 next 6
2022-05-12 17:55:45.729216: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa71f747200 of size 256 next 501
2022-05-12 17:55:45.729229: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa71f747300 of size 256 next 321
2022-05-12 17:55:45.729242: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa71f747400 of size 102760448 next 597
2022-05-12 17:55:45.729255: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa725947400 of size 102760448 next 1071
2022-05-12 17:55:45.729268: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa72bb47400 of size 102760448 next 553
2022-05-12 17:55:45.729280: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa731d47400 of size 102760448 next 685
2022-05-12 17:55:45.729293: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa737f47400 of size 102760448 next 754
2022-05-12 17:55:45.729306: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa73e147400 of size 25690112 next 1069
2022-05-12 17:55:45.729319: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa73f9c7400 of size 25690112 next 930
2022-05-12 17:55:45.729332: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa741247400 of size 3328 next 313
2022-05-12 17:55:45.729345: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa741248100 of size 256 next 902
2022-05-12 17:55:45.729357: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa741248200 of size 256 next 271
2022-05-12 17:55:45.729370: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa741248300 of size 25686272 next 514
2022-05-12 17:55:45.729383: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa742ac7400 of size 12544 next 445
2022-05-12 17:55:45.729397: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa742aca500 of size 25690112 next 19
2022-05-12 17:55:45.729409: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa74434a500 of size 25690112 next 464
2022-05-12 17:55:45.729422: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa745bca500 of size 25690112 next 665
2022-05-12 17:55:45.729435: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa74744a500 of size 25690112 next 444
2022-05-12 17:55:45.729448: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa748cca500 of size 25690112 next 630
2022-05-12 17:55:45.729461: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa74a54a500 of size 25690112 next 65
2022-05-12 17:55:45.729473: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa74bdca500 of size 25690112 next 772
2022-05-12 17:55:45.729486: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa74d64a500 of size 25690112 next 462
2022-05-12 17:55:45.729499: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa74eeca500 of size 3328 next 454
2022-05-12 17:55:45.729511: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa74eecb200 of size 25690112 next 338
2022-05-12 17:55:45.729524: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa75074b200 of size 25690112 next 910
2022-05-12 17:55:45.729541: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa751fcb200 of size 256 next 275
2022-05-12 17:55:45.729555: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa751fcb300 of size 256 next 602
2022-05-12 17:55:45.729568: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa751fcb400 of size 102760448 next 22
2022-05-12 17:55:45.729581: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7581cb400 of size 102760448 next 958
2022-05-12 17:55:45.729594: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa75e3cb400 of size 102760448 next 1042
2022-05-12 17:55:45.729607: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7645cb400 of size 102760448 next 315
2022-05-12 17:55:45.729620: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa76a7cb400 of size 102760448 next 720
2022-05-12 17:55:45.729633: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7709cb400 of size 25690112 next 1058
2022-05-12 17:55:45.729645: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa77224b400 of size 25690112 next 380
2022-05-12 17:55:45.729659: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa773acb400 of size 3328 next 390
2022-05-12 17:55:45.729672: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa773acc100 of size 256 next 786
2022-05-12 17:55:45.729684: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa773acc200 of size 256 next 938
2022-05-12 17:55:45.729697: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa773acc300 of size 25686272 next 579
2022-05-12 17:55:45.729710: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa77534b400 of size 12544 next 907
2022-05-12 17:55:45.729723: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa77534e500 of size 25690112 next 1047
2022-05-12 17:55:45.729736: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa776bce500 of size 25690112 next 839
2022-05-12 17:55:45.729749: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa77844e500 of size 25690112 next 57
2022-05-12 17:55:45.729762: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa779cce500 of size 25690112 next 528
2022-05-12 17:55:45.729775: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa77b54e500 of size 25690112 next 470
2022-05-12 17:55:45.729787: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa77cdce500 of size 25690112 next 981
2022-05-12 17:55:45.729800: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa77e64e500 of size 25690112 next 782
2022-05-12 17:55:45.729813: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa77fece500 of size 25690112 next 863
2022-05-12 17:55:45.729826: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa78174e500 of size 3328 next 545
2022-05-12 17:55:45.729839: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa78174f200 of size 25690112 next 1034
2022-05-12 17:55:45.729852: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa782fcf200 of size 25690112 next 757
2022-05-12 17:55:45.729865: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa78484f200 of size 256 next 932
2022-05-12 17:55:45.729878: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa78484f300 of size 256 next 524
2022-05-12 17:55:45.729891: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa78484f400 of size 102760448 next 328
2022-05-12 17:55:45.729904: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa78aa4f400 of size 102760448 next 934
2022-05-12 17:55:45.729917: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa790c4f400 of size 102760448 next 72
2022-05-12 17:55:45.729930: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa796e4f400 of size 102760448 next 286
2022-05-12 17:55:45.729943: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa79d04f400 of size 102760448 next 620
2022-05-12 17:55:45.729960: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a324f400 of size 25690112 next 854
2022-05-12 17:55:45.729973: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a4acf400 of size 25690112 next 340
2022-05-12 17:55:45.729986: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a634f400 of size 3328 next 819
2022-05-12 17:55:45.729999: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a6350100 of size 256 next 673
2022-05-12 17:55:45.730012: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a6350200 of size 256 next 824
2022-05-12 17:55:45.730025: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a6350300 of size 25686272 next 323
2022-05-12 17:55:45.730038: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a7bcf400 of size 12544 next 44
2022-05-12 17:55:45.730051: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a7bd2500 of size 25690112 next 1040
2022-05-12 17:55:45.730064: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7a9452500 of size 25690112 next 32
2022-05-12 17:55:45.730077: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7aacd2500 of size 25690112 next 422
2022-05-12 17:55:45.730089: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7ac552500 of size 25690112 next 389
2022-05-12 17:55:45.730102: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7addd2500 of size 25690112 next 870
2022-05-12 17:55:45.730115: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7af652500 of size 25690112 next 986
2022-05-12 17:55:45.730128: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7b0ed2500 of size 25690112 next 614
2022-05-12 17:55:45.730147: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7b2752500 of size 25690112 next 530
2022-05-12 17:55:45.730160: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7b3fd2500 of size 3328 next 591
2022-05-12 17:55:45.730173: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7b3fd3200 of size 25690112 next 748
2022-05-12 17:55:45.730185: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7b5853200 of size 25690112 next 738
2022-05-12 17:55:45.730198: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7b70d3200 of size 256 next 945
2022-05-12 17:55:45.730211: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7b70d3300 of size 256 next 692
2022-05-12 17:55:45.730224: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7b70d3400 of size 102760448 next 291
2022-05-12 17:55:45.730237: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7bd2d3400 of size 102760448 next 785
2022-05-12 17:55:45.730250: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7c34d3400 of size 102760448 next 455
2022-05-12 17:55:45.730263: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7c96d3400 of size 102760448 next 849
2022-05-12 17:55:45.730275: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7cf8d3400 of size 102760448 next 962
2022-05-12 17:55:45.730288: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7d5ad3400 of size 25690112 next 1026
2022-05-12 17:55:45.730301: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7d7353400 of size 25690112 next 302
2022-05-12 17:55:45.730314: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7d8bd3400 of size 3328 next 539
2022-05-12 17:55:45.730327: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7d8bd4100 of size 256 next 629
2022-05-12 17:55:45.730340: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7d8bd4200 of size 256 next 414
2022-05-12 17:55:45.730353: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7d8bd4300 of size 25686272 next 1033
2022-05-12 17:55:45.730370: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7da453400 of size 12544 next 75
2022-05-12 17:55:45.730384: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7da456500 of size 25690112 next 66
2022-05-12 17:55:45.730396: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7dbcd6500 of size 25690112 next 359
2022-05-12 17:55:45.730409: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7dd556500 of size 25690112 next 406
2022-05-12 17:55:45.730422: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7dedd6500 of size 25690112 next 926
2022-05-12 17:55:45.730435: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e0656500 of size 25690112 next 775
2022-05-12 17:55:45.730448: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e1ed6500 of size 25690112 next 8
2022-05-12 17:55:45.730461: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e3756500 of size 25690112 next 810
2022-05-12 17:55:45.730473: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e4fd6500 of size 25690112 next 1046
2022-05-12 17:55:45.730486: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e6856500 of size 3328 next 366
2022-05-12 17:55:45.730499: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e6857200 of size 25690112 next 865
2022-05-12 17:55:45.730535: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e80d7200 of size 25690112 next 1007
2022-05-12 17:55:45.730548: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e9957200 of size 256 next 791
2022-05-12 17:55:45.730561: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e9957300 of size 256 next 1015
2022-05-12 17:55:45.730574: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7e9957400 of size 102760448 next 700
2022-05-12 17:55:45.730587: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7efb57400 of size 102760448 next 1038
2022-05-12 17:55:45.730600: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7f5d57400 of size 102760448 next 761
2022-05-12 17:55:45.730613: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa7fbf57400 of size 102760448 next 527
2022-05-12 17:55:45.730626: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa802157400 of size 102760448 next 880
2022-05-12 17:55:45.730638: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa808357400 of size 25690112 next 1022
2022-05-12 17:55:45.730651: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa809bd7400 of size 25690112 next 886
2022-05-12 17:55:45.730664: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa80b457400 of size 3328 next 947
2022-05-12 17:55:45.730677: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa80b458100 of size 256 next 466
2022-05-12 17:55:45.730690: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa80b458200 of size 256 next 671
2022-05-12 17:55:45.730703: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa80b458300 of size 25686272 next 572
2022-05-12 17:55:45.730716: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa80ccd7400 of size 12544 next 402
2022-05-12 17:55:45.730728: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa80ccda500 of size 25690112 next 370
2022-05-12 17:55:45.730741: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa80e55a500 of size 25690112 next 510
2022-05-12 17:55:45.730754: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa80fdda500 of size 25690112 next 344
2022-05-12 17:55:45.730767: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa81165a500 of size 25690112 next 270
2022-05-12 17:55:45.730780: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa812eda500 of size 25690112 next 1070
2022-05-12 17:55:45.730796: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa81475a500 of size 25690112 next 332
2022-05-12 17:55:45.730810: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa815fda500 of size 25690112 next 763
2022-05-12 17:55:45.730822: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa81785a500 of size 25690112 next 575
2022-05-12 17:55:45.730835: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8190da500 of size 3328 next 1028
2022-05-12 17:55:45.730848: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8190db200 of size 25690112 next 659
2022-05-12 17:55:45.730861: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa81a95b200 of size 25690112 next 288
2022-05-12 17:55:45.730874: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa81c1db200 of size 256 next 919
2022-05-12 17:55:45.730886: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa81c1db300 of size 256 next 492
2022-05-12 17:55:45.730899: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa81c1db400 of size 102760448 next 988
2022-05-12 17:55:45.730912: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8223db400 of size 102760448 next 475
2022-05-12 17:55:45.730925: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8285db400 of size 102760448 next 368
2022-05-12 17:55:45.730938: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa82e7db400 of size 102760448 next 1017
2022-05-12 17:55:45.730951: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8349db400 of size 102760448 next 697
2022-05-12 17:55:45.730964: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa83abdb400 of size 25690112 next 556
2022-05-12 17:55:45.730976: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa83c45b400 of size 25690112 next 704
2022-05-12 17:55:45.730989: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa83dcdb400 of size 3328 next 363
2022-05-12 17:55:45.731002: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa83dcdc100 of size 256 next 1049
2022-05-12 17:55:45.731015: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa83dcdc200 of size 256 next 906
2022-05-12 17:55:45.731028: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa83dcdc300 of size 25686272 next 331
2022-05-12 17:55:45.731041: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa83f55b400 of size 12544 next 856
2022-05-12 17:55:45.731054: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa83f55e500 of size 25690112 next 523
2022-05-12 17:55:45.731067: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa840dde500 of size 25690112 next 622
2022-05-12 17:55:45.731079: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84265e500 of size 25690112 next 548
2022-05-12 17:55:45.731092: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa843ede500 of size 25690112 next 432
2022-05-12 17:55:45.731105: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84575e500 of size 25690112 next 654
2022-05-12 17:55:45.731117: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa846fde500 of size 25690112 next 942
2022-05-12 17:55:45.731135: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84885e500 of size 25690112 next 584
2022-05-12 17:55:45.731150: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84a0de500 of size 25690112 next 588
2022-05-12 17:55:45.731163: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84b95e500 of size 3328 next 726
2022-05-12 17:55:45.731175: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84b95f200 of size 25690112 next 71
2022-05-12 17:55:45.731188: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84d1df200 of size 25690112 next 1032
2022-05-12 17:55:45.731206: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84ea5f200 of size 256 next 265
2022-05-12 17:55:45.731219: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84ea5f300 of size 256 next 458
2022-05-12 17:55:45.731232: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa84ea5f400 of size 102760448 next 299
2022-05-12 17:55:45.731244: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa854c5f400 of size 102760448 next 936
2022-05-12 17:55:45.731257: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa85ae5f400 of size 102760448 next 898
2022-05-12 17:55:45.731270: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa86105f400 of size 102760448 next 377
2022-05-12 17:55:45.731282: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa86725f400 of size 102760448 next 838
2022-05-12 17:55:45.731295: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa86d45f400 of size 25690112 next 385
2022-05-12 17:55:45.731308: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa86ecdf400 of size 25690112 next 430
2022-05-12 17:55:45.731321: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa87055f400 of size 3328 next 274
2022-05-12 17:55:45.731334: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa870560100 of size 256 next 989
2022-05-12 17:55:45.731347: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa870560200 of size 256 next 670
2022-05-12 17:55:45.731359: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa870560300 of size 25686272 next 396
2022-05-12 17:55:45.731372: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa871ddf400 of size 12544 next 800
2022-05-12 17:55:45.731385: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa871de2500 of size 25690112 next 955
2022-05-12 17:55:45.731398: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa873662500 of size 25690112 next 848
2022-05-12 17:55:45.731410: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa874ee2500 of size 25690112 next 959
2022-05-12 17:55:45.731423: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa876762500 of size 25690112 next 827
2022-05-12 17:55:45.731436: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa877fe2500 of size 25690112 next 623
2022-05-12 17:55:45.731449: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa879862500 of size 25690112 next 1019
2022-05-12 17:55:45.731461: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa87b0e2500 of size 25690112 next 568
2022-05-12 17:55:45.731474: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa87c962500 of size 25690112 next 793
2022-05-12 17:55:45.731487: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa87e1e2500 of size 3328 next 914
2022-05-12 17:55:45.731500: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa87e1e3200 of size 25690112 next 861
2022-05-12 17:55:45.731512: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa87fa63200 of size 25690112 next 506
2022-05-12 17:55:45.731525: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 7fa8812e3200 of size 256 next 737
2022-05-12 17:55:45.731538: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8812e3300 of size 256 next 583
2022-05-12 17:55:45.731551: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8812e3400 of size 102760448 next 789
2022-05-12 17:55:45.731564: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8874e3400 of size 102760448 next 341
2022-05-12 17:55:45.731577: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa88d6e3400 of size 115748352 next 63
2022-05-12 17:55:45.731591: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa894546200 of size 256 next 795
2022-05-12 17:55:45.731604: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa894546300 of size 102760448 next 520
2022-05-12 17:55:45.731623: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa89a746300 of size 102760448 next 600
2022-05-12 17:55:45.731637: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a0946300 of size 25690112 next 952
2022-05-12 17:55:45.731650: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a21c6300 of size 25690112 next 821
2022-05-12 17:55:45.731663: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a3a46300 of size 3328 next 806
2022-05-12 17:55:45.731676: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a3a47000 of size 256 next 473
2022-05-12 17:55:45.731689: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a3a47100 of size 256 next 860
2022-05-12 17:55:45.731702: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a3a47200 of size 25686272 next 55
2022-05-12 17:55:45.731715: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a52c6300 of size 12544 next 587
2022-05-12 17:55:45.731728: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a52c9400 of size 25690112 next 657
2022-05-12 17:55:45.731741: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a6b49400 of size 25690112 next 596
2022-05-12 17:55:45.731754: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a83c9400 of size 25690112 next 966
2022-05-12 17:55:45.731767: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8a9c49400 of size 25690112 next 1068
2022-05-12 17:55:45.731780: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8ab4c9400 of size 25690112 next 823
2022-05-12 17:55:45.731792: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8acd49400 of size 25690112 next 381
2022-05-12 17:55:45.731805: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8ae5c9400 of size 25690112 next 923
2022-05-12 17:55:45.731818: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8afe49400 of size 25690112 next 780
2022-05-12 17:55:45.731831: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8b16c9400 of size 3328 next 457
2022-05-12 17:55:45.731844: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8b16ca100 of size 25690112 next 816
2022-05-12 17:55:45.731857: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8b2f4a100 of size 25690112 next 781
2022-05-12 17:55:45.731870: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8b47ca100 of size 256 next 26
2022-05-12 17:55:45.731882: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8b47ca200 of size 256 next 69
2022-05-12 17:55:45.731896: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8b47ca300 of size 102760448 next 312
2022-05-12 17:55:45.731909: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8ba9ca300 of size 102760448 next 343
2022-05-12 17:55:45.731921: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8c0bca300 of size 102760448 next 483
2022-05-12 17:55:45.731934: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8c6dca300 of size 102760448 next 949
2022-05-12 17:55:45.731947: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8ccfca300 of size 102760448 next 740
2022-05-12 17:55:45.731960: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d31ca300 of size 25690112 next 678
2022-05-12 17:55:45.731975: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d4a4a300 of size 25690112 next 449
2022-05-12 17:55:45.731988: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d62ca300 of size 3328 next 876
2022-05-12 17:55:45.732001: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d62cb000 of size 256 next 996
2022-05-12 17:55:45.732013: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d62cb100 of size 256 next 560
2022-05-12 17:55:45.732030: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d62cb200 of size 25686272 next 375
2022-05-12 17:55:45.732043: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d7b4a300 of size 12544 next 873
2022-05-12 17:55:45.732056: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d7b4d400 of size 25690112 next 263
2022-05-12 17:55:45.732069: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8d93cd400 of size 25690112 next 843
2022-05-12 17:55:45.732082: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8dac4d400 of size 25690112 next 770
2022-05-12 17:55:45.732094: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8dc4cd400 of size 25690112 next 525
2022-05-12 17:55:45.732107: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8ddd4d400 of size 25690112 next 64
2022-05-12 17:55:45.732120: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8df5cd400 of size 25690112 next 645
2022-05-12 17:55:45.732140: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8e0e4d400 of size 25690112 next 580
2022-05-12 17:55:45.732154: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8e26cd400 of size 25690112 next 705
2022-05-12 17:55:45.732167: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8e3f4d400 of size 3328 next 393
2022-05-12 17:55:45.732180: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8e3f4e100 of size 25690112 next 742
2022-05-12 17:55:45.732193: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8e57ce100 of size 25690112 next 767
2022-05-12 17:55:45.732206: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8e704e100 of size 256 next 991
2022-05-12 17:55:45.732219: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8e704e200 of size 256 next 360
2022-05-12 17:55:45.732232: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8e704e300 of size 102760448 next 616
2022-05-12 17:55:45.732245: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8ed24e300 of size 102760448 next 1000
2022-05-12 17:55:45.732258: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8f344e300 of size 102760448 next 655
2022-05-12 17:55:45.732271: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8f964e300 of size 102760448 next 352
2022-05-12 17:55:45.732283: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa8ff84e300 of size 102760448 next 371
2022-05-12 17:55:45.732296: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa905a4e300 of size 25690112 next 415
2022-05-12 17:55:45.732309: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9072ce300 of size 25690112 next 1012
2022-05-12 17:55:45.732322: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa908b4e300 of size 3328 next 58
2022-05-12 17:55:45.732335: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa908b4f000 of size 256 next 951
2022-05-12 17:55:45.732348: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa908b4f100 of size 256 next 1054
2022-05-12 17:55:45.732361: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa908b4f200 of size 25686272 next 401
2022-05-12 17:55:45.732374: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa90a3ce300 of size 12544 next 901
2022-05-12 17:55:45.732387: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa90a3d1400 of size 25690112 next 805
2022-05-12 17:55:45.732400: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa90bc51400 of size 25690112 next 433
2022-05-12 17:55:45.732413: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa90d4d1400 of size 25690112 next 617
2022-05-12 17:55:45.732426: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa90ed51400 of size 25690112 next 792
2022-05-12 17:55:45.732442: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9105d1400 of size 25690112 next 801
2022-05-12 17:55:45.732456: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa911e51400 of size 25690112 next 9
2022-05-12 17:55:45.732469: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9136d1400 of size 25690112 next 682
2022-05-12 17:55:45.732482: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa914f51400 of size 25690112 next 426
2022-05-12 17:55:45.732495: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9167d1400 of size 3328 next 752
2022-05-12 17:55:45.732507: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9167d2100 of size 25690112 next 967
2022-05-12 17:55:45.732520: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa918052100 of size 25690112 next 272
2022-05-12 17:55:45.732533: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9198d2100 of size 256 next 648
2022-05-12 17:55:45.732546: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9198d2200 of size 256 next 658
2022-05-12 17:55:45.732559: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9198d2300 of size 102760448 next 818
2022-05-12 17:55:45.732572: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa91fad2300 of size 102760448 next 438
2022-05-12 17:55:45.732584: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa925cd2300 of size 102760448 next 749
2022-05-12 17:55:45.732597: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa92bed2300 of size 102760448 next 787
2022-05-12 17:55:45.732610: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9320d2300 of size 102760448 next 884
2022-05-12 17:55:45.732623: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9382d2300 of size 25690112 next 960
2022-05-12 17:55:45.732636: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa939b52300 of size 25690112 next 478
2022-05-12 17:55:45.732661: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa93b3d2300 of size 3328 next 358
2022-05-12 17:55:45.732674: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa93b3d3000 of size 256 next 581
2022-05-12 17:55:45.732685: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa93b3d3100 of size 256 next 877
2022-05-12 17:55:45.732697: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa93b3d3200 of size 25686272 next 779
2022-05-12 17:55:45.732709: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa93cc52300 of size 12544 next 611
2022-05-12 17:55:45.732721: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa93cc55400 of size 25690112 next 285
2022-05-12 17:55:45.732733: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa93e4d5400 of size 25690112 next 316
2022-05-12 17:55:45.732744: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa93fd55400 of size 25690112 next 476
2022-05-12 17:55:45.732756: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9415d5400 of size 25690112 next 994
2022-05-12 17:55:45.732768: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa942e55400 of size 25690112 next 643
2022-05-12 17:55:45.732780: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9446d5400 of size 25690112 next 728
2022-05-12 17:55:45.732791: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa945f55400 of size 25690112 next 911
2022-05-12 17:55:45.732803: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9477d5400 of size 25690112 next 773
2022-05-12 17:55:45.732815: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa949055400 of size 3328 next 1044
2022-05-12 17:55:45.732827: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa949056100 of size 25690112 next 388
2022-05-12 17:55:45.732843: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa94a8d6100 of size 25690112 next 482
2022-05-12 17:55:45.732855: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa94c156100 of size 256 next 874
2022-05-12 17:55:45.732867: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa94c156200 of size 256 next 411
2022-05-12 17:55:45.732879: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa94c156300 of size 102760448 next 1006
2022-05-12 17:55:45.732891: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa952356300 of size 102760448 next 493
2022-05-12 17:55:45.732903: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa958556300 of size 102760448 next 802
2022-05-12 17:55:45.732914: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa95e756300 of size 102760448 next 508
2022-05-12 17:55:45.732926: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa964956300 of size 102760448 next 788
2022-05-12 17:55:45.732938: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa96ab56300 of size 25690112 next 606
2022-05-12 17:55:45.732950: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa96c3d6300 of size 25690112 next 625
2022-05-12 17:55:45.732962: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa96dc56300 of size 3328 next 333
2022-05-12 17:55:45.732974: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa96dc57000 of size 256 next 1016
2022-05-12 17:55:45.732986: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa96dc57100 of size 256 next 77
2022-05-12 17:55:45.732997: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa96dc57200 of size 25686272 next 940
2022-05-12 17:55:45.733009: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa96f4d6300 of size 12544 next 357
2022-05-12 17:55:45.733021: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa96f4d9400 of size 25690112 next 964
2022-05-12 17:55:45.733033: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa970d59400 of size 25690112 next 953
2022-05-12 17:55:45.733045: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9725d9400 of size 25690112 next 769
2022-05-12 17:55:45.733057: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa973e59400 of size 25690112 next 916
2022-05-12 17:55:45.733068: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9756d9400 of size 25690112 next 461
2022-05-12 17:55:45.733080: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa976f59400 of size 25690112 next 1023
2022-05-12 17:55:45.733092: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9787d9400 of size 25690112 next 481
2022-05-12 17:55:45.733104: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa97a059400 of size 25690112 next 675
2022-05-12 17:55:45.733116: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa97b8d9400 of size 3328 next 282
2022-05-12 17:55:45.733127: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa97b8da100 of size 25690112 next 326
2022-05-12 17:55:45.733145: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa97d15a100 of size 25690112 next 693
2022-05-12 17:55:45.733157: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa97e9da100 of size 256 next 686
2022-05-12 17:55:45.733169: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa97e9da200 of size 256 next 871
2022-05-12 17:55:45.733181: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa97e9da300 of size 102760448 next 365
2022-05-12 17:55:45.733193: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa984bda300 of size 102760448 next 799
2022-05-12 17:55:45.733205: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa98adda300 of size 102760448 next 1076
2022-05-12 17:55:45.733217: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa990fda300 of size 102760448 next 404
2022-05-12 17:55:45.733234: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9971da300 of size 102760448 next 859
2022-05-12 17:55:45.733247: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa99d3da300 of size 25690112 next 420
2022-05-12 17:55:45.733258: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa99ec5a300 of size 25690112 next 724
2022-05-12 17:55:45.733270: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a04da300 of size 3328 next 836
2022-05-12 17:55:45.733282: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a04db000 of size 256 next 296
2022-05-12 17:55:45.733294: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a04db100 of size 256 next 463
2022-05-12 17:55:45.733306: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a04db200 of size 25686272 next 409
2022-05-12 17:55:45.733318: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a1d5a300 of size 12544 next 931
2022-05-12 17:55:45.733330: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a1d5d400 of size 25690112 next 997
2022-05-12 17:55:45.733341: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a35dd400 of size 25690112 next 498
2022-05-12 17:55:45.733353: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a4e5d400 of size 25690112 next 491
2022-05-12 17:55:45.733365: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a66dd400 of size 25690112 next 1037
2022-05-12 17:55:45.733377: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a7f5d400 of size 25690112 next 290
2022-05-12 17:55:45.733389: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9a97dd400 of size 25690112 next 5
2022-05-12 17:55:45.733400: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9ab05d400 of size 25690112 next 766
2022-05-12 17:55:45.733412: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9ac8dd400 of size 25690112 next 1063
2022-05-12 17:55:45.733424: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9ae15d400 of size 3328 next 822
2022-05-12 17:55:45.733436: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9ae15e100 of size 25690112 next 47
2022-05-12 17:55:45.733448: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9af9de100 of size 25690112 next 669
2022-05-12 17:55:45.733460: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9b125e100 of size 256 next 736
2022-05-12 17:55:45.733472: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9b125e200 of size 256 next 624
2022-05-12 17:55:45.733484: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9b125e300 of size 102760448 next 536
2022-05-12 17:55:45.733496: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9b745e300 of size 102760448 next 1064
2022-05-12 17:55:45.733507: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9bd65e300 of size 102760448 next 379
2022-05-12 17:55:45.733520: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9c385e300 of size 193536000 next 1036
2022-05-12 17:55:45.733532: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9cf0f0300 of size 256 next 1039
2022-05-12 17:55:45.733544: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9cf0f0400 of size 102760448 next 1059
2022-05-12 17:55:45.733556: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9d52f0400 of size 25690112 next 345
2022-05-12 17:55:45.733568: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9d6b70400 of size 25690112 next 896
2022-05-12 17:55:45.733579: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9d83f0400 of size 25690112 next 847
2022-05-12 17:55:45.733591: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9d9c70400 of size 25690112 next 372
2022-05-12 17:55:45.733607: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9db4f0400 of size 25690112 next 739
2022-05-12 17:55:45.733619: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9dcd70400 of size 25690112 next 713
2022-05-12 17:55:45.733631: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9de5f0400 of size 25690112 next 1043
2022-05-12 17:55:45.733643: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9dfe70400 of size 19668992 next 367
2022-05-12 17:55:45.733655: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9e1132400 of size 25690112 next 612
2022-05-12 17:55:45.733666: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9e29b2400 of size 25690112 next 722
2022-05-12 17:55:45.733678: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9e4232400 of size 25690112 next 7
2022-05-12 17:55:45.733690: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9e5ab2400 of size 102760448 next 549
2022-05-12 17:55:45.733702: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9ebcb2400 of size 102760448 next 965
2022-05-12 17:55:45.733714: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9f1eb2400 of size 102760448 next 812
2022-05-12 17:55:45.733726: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9f80b2400 of size 102760448 next 361
2022-05-12 17:55:45.733738: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7fa9fe2b2400 of size 102760448 next 59
2022-05-12 17:55:45.733750: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa044b2400 of size 25690112 next 552
2022-05-12 17:55:45.733761: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa05d32400 of size 25690112 next 48
2022-05-12 17:55:45.733773: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa075b2400 of size 25690112 next 1029
2022-05-12 17:55:45.733785: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa08e32400 of size 25690112 next 46
2022-05-12 17:55:45.733797: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa0a6b2400 of size 25690112 next 456
2022-05-12 17:55:45.733809: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa0bf32400 of size 25690112 next 348
2022-05-12 17:55:45.733820: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa0d7b2400 of size 25690112 next 892
2022-05-12 17:55:45.733832: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa0f032400 of size 25690112 next 526
2022-05-12 17:55:45.733844: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa108b2400 of size 25690112 next 928
2022-05-12 17:55:45.733856: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa12132400 of size 19668992 next 599
2022-05-12 17:55:45.733867: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa133f4400 of size 25690112 next 541
2022-05-12 17:55:45.733879: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa14c74400 of size 25690112 next 31
2022-05-12 17:55:45.733891: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa164f4400 of size 25690112 next 1010
2022-05-12 17:55:45.733903: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa17d74400 of size 102760448 next 1051
2022-05-12 17:55:45.733915: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa1df74400 of size 102760448 next 571
2022-05-12 17:55:45.733927: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa24174400 of size 102760448 next 400
2022-05-12 17:55:45.733939: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa2a374400 of size 102760448 next 694
2022-05-12 17:55:45.733950: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa30574400 of size 102760448 next 922
2022-05-12 17:55:45.733962: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa36774400 of size 25690112 next 834
2022-05-12 17:55:45.733978: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa37ff4400 of size 25690112 next 790
2022-05-12 17:55:45.733990: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa39874400 of size 25690112 next 278
2022-05-12 17:55:45.734002: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa3b0f4400 of size 25690112 next 837
2022-05-12 17:55:45.734014: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa3c974400 of size 25690112 next 691
2022-05-12 17:55:45.734025: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa3e1f4400 of size 25690112 next 490
2022-05-12 17:55:45.734037: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa3fa74400 of size 25690112 next 723
2022-05-12 17:55:45.734049: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa412f4400 of size 25690112 next 550
2022-05-12 17:55:45.734061: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa42b74400 of size 25690112 next 511
2022-05-12 17:55:45.734073: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa443f4400 of size 19668992 next 1008
2022-05-12 17:55:45.734084: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa456b6400 of size 25690112 next 774
2022-05-12 17:55:45.734096: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa46f36400 of size 25690112 next 1018
2022-05-12 17:55:45.734108: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa487b6400 of size 25690112 next 441
2022-05-12 17:55:45.734120: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa4a036400 of size 102760448 next 73
2022-05-12 17:55:45.734137: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa50236400 of size 102760448 next 974
2022-05-12 17:55:45.734151: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa56436400 of size 102760448 next 715
2022-05-12 17:55:45.734163: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa5c636400 of size 102760448 next 948
2022-05-12 17:55:45.734174: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa62836400 of size 102760448 next 565
2022-05-12 17:55:45.734186: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa68a36400 of size 25690112 next 479
2022-05-12 17:55:45.734198: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa6a2b6400 of size 25690112 next 56
2022-05-12 17:55:45.734210: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa6bb36400 of size 3328 next 778
2022-05-12 17:55:45.734222: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa6bb37100 of size 25690112 next 557
2022-05-12 17:55:45.734234: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa6d3b7100 of size 25690112 next 750
2022-05-12 17:55:45.734245: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa6ec37100 of size 256 next 80
2022-05-12 17:55:45.734257: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa6ec37200 of size 256 next 418
2022-05-12 17:55:45.734269: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa6ec37300 of size 25690112 next 585
2022-05-12 17:55:45.734281: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa704b7300 of size 25690112 next 618
2022-05-12 17:55:45.734292: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa71d37300 of size 25690112 next 855
2022-05-12 17:55:45.734304: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa735b7300 of size 25690112 next 776
2022-05-12 17:55:45.734316: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa74e37300 of size 25690112 next 698
2022-05-12 17:55:45.734327: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa766b7300 of size 19668992 next 905
2022-05-12 17:55:45.734339: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa77979300 of size 25690112 next 427
2022-05-12 17:55:45.734356: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa791f9300 of size 3328 next 435
2022-05-12 17:55:45.734368: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa791fa000 of size 25690112 next 378
2022-05-12 17:55:45.734380: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa7aa7a000 of size 25690112 next 626
2022-05-12 17:55:45.734391: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa7c2fa000 of size 256 next 985
2022-05-12 17:55:45.734403: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa7c2fa100 of size 256 next 268
2022-05-12 17:55:45.734415: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa7c2fa200 of size 102760448 next 542
2022-05-12 17:55:45.734427: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa824fa200 of size 102760448 next 334
2022-05-12 17:55:45.734439: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa886fa200 of size 102760448 next 468
2022-05-12 17:55:45.734451: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa8e8fa200 of size 102760448 next 16
2022-05-12 17:55:45.734463: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa94afa200 of size 102760448 next 1020
2022-05-12 17:55:45.734475: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa9acfa200 of size 25690112 next 850
2022-05-12 17:55:45.734487: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa9c57a200 of size 25690112 next 1011
2022-05-12 17:55:45.734499: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa9ddfa200 of size 3328 next 319
2022-05-12 17:55:45.734510: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa9ddfaf00 of size 256 next 450
2022-05-12 17:55:45.734522: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa9ddfb000 of size 256 next 1002
2022-05-12 17:55:45.734534: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa9ddfb100 of size 25686272 next 897
2022-05-12 17:55:45.734546: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa9f67a200 of size 12544 next 1009
2022-05-12 17:55:45.734558: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faa9f67d300 of size 25690112 next 915
2022-05-12 17:55:45.734570: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaa0efd300 of size 25690112 next 54
2022-05-12 17:55:45.734582: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaa277d300 of size 25690112 next 62
2022-05-12 17:55:45.734594: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaa3ffd300 of size 25690112 next 1030
2022-05-12 17:55:45.734605: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaa587d300 of size 25690112 next 689
2022-05-12 17:55:45.734617: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaa70fd300 of size 25690112 next 765
2022-05-12 17:55:45.734629: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaa897d300 of size 25690112 next 324
2022-05-12 17:55:45.734641: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaaa1fd300 of size 25690112 next 760
2022-05-12 17:55:45.734653: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaaba7d300 of size 3328 next 832
2022-05-12 17:55:45.734664: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaaba7e000 of size 25690112 next 543
2022-05-12 17:55:45.734676: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaad2fe000 of size 25690112 next 835
2022-05-12 17:55:45.734688: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] Free  at 7faaaeb7e000 of size 256 next 714
2022-05-12 17:55:45.734700: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaaeb7e100 of size 256 next 753
2022-05-12 17:55:45.734712: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faaaeb7e200 of size 102760448 next 666
2022-05-12 17:55:45.734728: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faab4d7e200 of size 102760448 next 820
2022-05-12 17:55:45.734741: I tensorflow/core/common_runtime/bfc_allocator.cc:1060] InUse at 7faabaf7e200 of size 125246976 next 18446744073709551615
2022-05-12 17:55:45.734753: I tensorflow/core/common_runtime/bfc_allocator.cc:1065]      Summary of in-use Chunks by size: 
2022-05-12 17:55:45.734771: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 393 Chunks of size 256 totalling 98.2KiB
2022-05-12 17:55:45.734786: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 512 totalling 512B
2022-05-12 17:55:45.734800: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 1280 totalling 1.2KiB
2022-05-12 17:55:45.734816: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 47 Chunks of size 3328 totalling 152.8KiB
2022-05-12 17:55:45.734830: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 3840 totalling 3.8KiB
2022-05-12 17:55:45.734844: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 4352 totalling 4.2KiB
2022-05-12 17:55:45.734858: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 4864 totalling 4.8KiB
2022-05-12 17:55:45.734872: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 46 Chunks of size 8192 totalling 368.0KiB
2022-05-12 17:55:45.734887: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 8448 totalling 16.5KiB
2022-05-12 17:55:45.734901: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 8704 totalling 8.5KiB
2022-05-12 17:55:45.734914: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 9216 totalling 9.0KiB
2022-05-12 17:55:45.734929: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 70 Chunks of size 12544 totalling 857.5KiB
2022-05-12 17:55:45.734944: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 13056 totalling 12.8KiB
2022-05-12 17:55:45.734958: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 14080 totalling 13.8KiB
2022-05-12 17:55:45.734972: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 14336 totalling 28.0KiB
2022-05-12 17:55:45.734987: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 14592 totalling 14.2KiB
2022-05-12 17:55:45.735001: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 3 Chunks of size 16384 totalling 48.0KiB
2022-05-12 17:55:45.735015: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 17152 totalling 16.8KiB
2022-05-12 17:55:45.735029: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 18176 totalling 17.8KiB
2022-05-12 17:55:45.735043: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 19456 totalling 19.0KiB
2022-05-12 17:55:45.735057: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 22272 totalling 21.8KiB
2022-05-12 17:55:45.735072: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 5 Chunks of size 32768 totalling 160.0KiB
2022-05-12 17:55:45.735086: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 3 Chunks of size 122880 totalling 360.0KiB
2022-05-12 17:55:45.735101: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 152832 totalling 149.2KiB
2022-05-12 17:55:45.735115: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 186112 totalling 181.8KiB
2022-05-12 17:55:45.735130: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 4194304 totalling 8.00MiB
2022-05-12 17:55:45.735151: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 4242432 totalling 4.05MiB
2022-05-12 17:55:45.735166: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 4244736 totalling 4.05MiB
2022-05-12 17:55:45.735179: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 4317184 totalling 4.12MiB
2022-05-12 17:55:45.735194: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 13 Chunks of size 16777216 totalling 208.00MiB
2022-05-12 17:55:45.735214: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 16789760 totalling 16.01MiB
2022-05-12 17:55:45.735229: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 17825792 totalling 17.00MiB
2022-05-12 17:55:45.735243: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 19398656 totalling 18.50MiB
2022-05-12 17:55:45.735258: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 5 Chunks of size 19668992 totalling 93.79MiB
2022-05-12 17:55:45.735272: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 20447232 totalling 19.50MiB
2022-05-12 17:55:45.735287: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 19 Chunks of size 25686272 totalling 465.43MiB
2022-05-12 17:55:45.735301: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 285 Chunks of size 25690112 totalling 6.82GiB
2022-05-12 17:55:45.735316: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 28377088 totalling 27.06MiB
2022-05-12 17:55:45.735330: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 29370624 totalling 28.01MiB
2022-05-12 17:55:45.735345: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 30974464 totalling 29.54MiB
2022-05-12 17:55:45.735359: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 42262528 totalling 40.30MiB
2022-05-12 17:55:45.735374: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 44375040 totalling 42.32MiB
2022-05-12 17:55:45.735388: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 49799936 totalling 47.49MiB
2022-05-12 17:55:45.735403: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 5 Chunks of size 67108864 totalling 320.00MiB
2022-05-12 17:55:45.735417: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 74461952 totalling 71.01MiB
2022-05-12 17:55:45.735432: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 77594624 totalling 74.00MiB
2022-05-12 17:55:45.735446: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 78507008 totalling 74.87MiB
2022-05-12 17:55:45.735460: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 81788928 totalling 78.00MiB
2022-05-12 17:55:45.735475: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 98566144 totalling 94.00MiB
2022-05-12 17:55:45.735489: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 114 Chunks of size 102760448 totalling 10.91GiB
2022-05-12 17:55:45.735504: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 115748352 totalling 110.39MiB
2022-05-12 17:55:45.735519: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 125246976 totalling 119.44MiB
2022-05-12 17:55:45.735534: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 151389184 totalling 144.38MiB
2022-05-12 17:55:45.735549: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 2 Chunks of size 173080576 totalling 330.12MiB
2022-05-12 17:55:45.735564: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 176132096 totalling 167.97MiB
2022-05-12 17:55:45.735578: I tensorflow/core/common_runtime/bfc_allocator.cc:1068] 1 Chunks of size 193536000 totalling 184.57MiB
2022-05-12 17:55:45.735593: I tensorflow/core/common_runtime/bfc_allocator.cc:1072] Sum Total of in-use chunks: 20.51GiB
2022-05-12 17:55:45.735607: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] total_region_allocated_bytes_: 22018981888 memory_limit_: 22018981888 available bytes: 0 curr_region_allocation_bytes_: 44037963776
2022-05-12 17:55:45.735632: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] Stats: 
Limit:                     22018981888
InUse:                     22018981376
MaxInUse:                  22018981376
NumAllocs:                       24681
MaxAllocSize:                299598848
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2022-05-12 17:55:45.735753: W tensorflow/core/common_runtime/bfc_allocator.cc:468] ****************************************************************************************************
2022-05-12 17:55:45.735793: W tensorflow/core/framework/op_kernel.cc:1680] Resource exhausted: failed to allocate memory
Traceback (most recent call last):
  File "run_fine_tuning_bert4keras_models.py", line 355, in <module>
    callbacks=[evaluator]
  File "/data0/zhaoxi9/miniconda3/envs/py37tf2/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py", line 1193, in fit
    tmp_logs = self.train_function(iterator)
  File "/data0/zhaoxi9/miniconda3/envs/py37tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 885, in __call__
    result = self._call(*args, **kwds)
  File "/data0/zhaoxi9/miniconda3/envs/py37tf2/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py", line 917, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File "/data0/zhaoxi9/miniconda3/envs/py37tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 3040, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File "/data0/zhaoxi9/miniconda3/envs/py37tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 1964, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/data0/zhaoxi9/miniconda3/envs/py37tf2/lib/python3.7/site-packages/tensorflow/python/eager/function.py", line 596, in call
    ctx=ctx)
  File "/data0/zhaoxi9/miniconda3/envs/py37tf2/lib/python3.7/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.ResourceExhaustedError:  failed to allocate memory
	 [[node model_1/Transformer-FeedForward/dense/add_47 (defined at /data0/zhaoxi9/miniconda3/envs/py37tf2/lib/python3.7/site-packages/bert4keras/backend.py:45) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_38798]

Function call stack:
train_function

2022-05-12 17:55:46.073552: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
