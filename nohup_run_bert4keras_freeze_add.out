nohup: ignoring input
2.6.0
2.6.0
0.11.3
Namespace(batch_size=256, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_L-12_H-768_A-12/bert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_L-12_H-768_A-12/bert_config.json', dropout=0.5, epochs=10000, freeze=True, gpu='2', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='bert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_L-12_H-768_A-12/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_travel': 0, 'news_stock': 1, 'news_agriculture': 2, 'news_sports': 3, 'news_house': 4, 'news_tech': 5, 'news_edu': 6, 'news_game': 7, 'news_culture': 8, 'news_world': 9, 'news_story': 10, 'news_finance': 11, 'news_military': 12, 'news_entertainment': 13, 'news_car': 14}
index_labels_dict={0: 'news_travel', 1: 'news_stock', 2: 'news_agriculture', 3: 'news_sports', 4: 'news_house', 5: 'news_tech', 6: 'news_edu', 7: 'news_game', 8: 'news_culture', 9: 'news_world', 10: 'news_story', 11: 'news_finance', 12: 'news_military', 13: 'news_entertainment', 14: 'news_car'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-11 16:34:32.892619: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-11 16:34:33.937884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22139 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:83:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          
                                                                 Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
                                                                 Transformer-0-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
                                                                 Transformer-1-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
                                                                 Transformer-2-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
                                                                 Transformer-3-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
                                                                 Transformer-4-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
                                                                 Transformer-5-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
                                                                 Transformer-6-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
                                                                 Transformer-7-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
                                                                 Transformer-8-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
                                                                 Transformer-9-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
                                                                 Transformer-10-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0
                                                                 Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
                                                                 Transformer-11-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 768)          0           Transformer-11-FeedForward-Norm[0
__________________________________________________________________________________________________
dropout (Dropout)               (None, 768)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           11535       dropout[0][0]                    
==================================================================================================
Total params: 101,688,591
Trainable params: 11,535
Non-trainable params: 101,677,056
__________________________________________________________________________________________________
2022-05-11 16:34:37.643957: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
188/188 - 111s - loss: 1.7339 - accuracy: 0.4711
dev acc=53.90%
test acc=53.97%
Epoch 2/10000
188/188 - 98s - loss: 1.4122 - accuracy: 0.5337
dev acc=54.07%
test acc=54.81%
Epoch 3/10000
188/188 - 98s - loss: 1.3813 - accuracy: 0.5383
dev acc=54.05%
Epoch 4/10000
188/188 - 98s - loss: 1.3725 - accuracy: 0.5369
dev acc=54.44%
test acc=54.92%
Epoch 5/10000
188/188 - 98s - loss: 1.3653 - accuracy: 0.5400
dev acc=54.46%
test acc=54.95%
Epoch 6/10000
188/188 - 99s - loss: 1.3622 - accuracy: 0.5399
dev acc=54.61%
test acc=54.87%
Epoch 7/10000
188/188 - 98s - loss: 1.3525 - accuracy: 0.5429
dev acc=54.57%
Epoch 8/10000
188/188 - 98s - loss: 1.3602 - accuracy: 0.5400
dev acc=54.72%
test acc=55.17%
Epoch 9/10000
188/188 - 98s - loss: 1.3561 - accuracy: 0.5408
dev acc=54.89%
test acc=55.20%
Epoch 10/10000
188/188 - 99s - loss: 1.3520 - accuracy: 0.5406
dev acc=55.02%
test acc=55.25%
Epoch 11/10000
188/188 - 98s - loss: 1.3498 - accuracy: 0.5462
dev acc=54.87%
Epoch 12/10000
188/188 - 98s - loss: 1.3505 - accuracy: 0.5417
dev acc=55.08%
test acc=55.16%
Epoch 13/10000
188/188 - 98s - loss: 1.3512 - accuracy: 0.5393
dev acc=55.02%
Epoch 14/10000
188/188 - 98s - loss: 1.3537 - accuracy: 0.5427
dev acc=55.00%
Epoch 15/10000
188/188 - 99s - loss: 1.3521 - accuracy: 0.5407
dev acc=54.85%
Epoch 16/10000
188/188 - 99s - loss: 1.3538 - accuracy: 0.5398
dev acc=54.74%
Epoch 17/10000
188/188 - 99s - loss: 1.3510 - accuracy: 0.5413
dev acc=54.97%
time used=2259.5s
2022-05-11 17:12:07.408335: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
run_bert4keras_freeze_add.sh: line 2: $'\r': command not found
2.6.0
2.6.0
0.11.3
Namespace(batch_size=256, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_bert_wwm_L-12_H-768_A-12/publish/bert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_bert_wwm_L-12_H-768_A-12/publish/bert_config.json', dropout=0.5, epochs=10000, freeze=True, gpu='2', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='bert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_bert_wwm_L-12_H-768_A-12/publish/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_culture': 0, 'news_house': 1, 'news_military': 2, 'news_story': 3, 'news_world': 4, 'news_sports': 5, 'news_agriculture': 6, 'news_game': 7, 'news_finance': 8, 'news_car': 9, 'news_travel': 10, 'news_stock': 11, 'news_tech': 12, 'news_edu': 13, 'news_entertainment': 14}
index_labels_dict={0: 'news_culture', 1: 'news_house', 2: 'news_military', 3: 'news_story', 4: 'news_world', 5: 'news_sports', 6: 'news_agriculture', 7: 'news_game', 8: 'news_finance', 9: 'news_car', 10: 'news_travel', 11: 'news_stock', 12: 'news_tech', 13: 'news_edu', 14: 'news_entertainment'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-11 17:12:15.950348: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-11 17:12:17.129895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22139 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:83:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          
                                                                 Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
                                                                 Transformer-0-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
                                                                 Transformer-1-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
                                                                 Transformer-2-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
                                                                 Transformer-3-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
                                                                 Transformer-4-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
                                                                 Transformer-5-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
                                                                 Transformer-6-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
                                                                 Transformer-7-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
                                                                 Transformer-8-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
                                                                 Transformer-9-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
                                                                 Transformer-10-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0
                                                                 Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
                                                                 Transformer-11-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 768)          0           Transformer-11-FeedForward-Norm[0
__________________________________________________________________________________________________
dropout (Dropout)               (None, 768)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           11535       dropout[0][0]                    
==================================================================================================
Total params: 101,688,591
Trainable params: 11,535
Non-trainable params: 101,677,056
__________________________________________________________________________________________________
2022-05-11 17:12:20.761670: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
188/188 - 109s - loss: 1.7583 - accuracy: 0.4656
dev acc=53.92%
test acc=53.83%
Epoch 2/10000
188/188 - 98s - loss: 1.4254 - accuracy: 0.5302
dev acc=54.20%
test acc=54.44%
Epoch 3/10000
188/188 - 98s - loss: 1.3926 - accuracy: 0.5341
dev acc=54.37%
test acc=54.90%
Epoch 4/10000
188/188 - 98s - loss: 1.3800 - accuracy: 0.5370
dev acc=54.65%
test acc=54.88%
Epoch 5/10000
188/188 - 98s - loss: 1.3750 - accuracy: 0.5378
dev acc=54.33%
Epoch 6/10000
188/188 - 98s - loss: 1.3668 - accuracy: 0.5391
dev acc=54.46%
Epoch 7/10000
188/188 - 98s - loss: 1.3631 - accuracy: 0.5403
dev acc=54.80%
test acc=55.04%
Epoch 8/10000
188/188 - 98s - loss: 1.3675 - accuracy: 0.5375
dev acc=54.69%
Epoch 9/10000
188/188 - 98s - loss: 1.3642 - accuracy: 0.5402
dev acc=54.76%
Epoch 10/10000
188/188 - 98s - loss: 1.3599 - accuracy: 0.5400
dev acc=54.76%
Epoch 11/10000
188/188 - 98s - loss: 1.3573 - accuracy: 0.5471
dev acc=54.74%
Epoch 12/10000
188/188 - 99s - loss: 1.3589 - accuracy: 0.5420
dev acc=54.84%
test acc=55.20%
Epoch 13/10000
188/188 - 99s - loss: 1.3605 - accuracy: 0.5403
dev acc=54.93%
test acc=55.11%
Epoch 14/10000
188/188 - 98s - loss: 1.3626 - accuracy: 0.5404
dev acc=55.10%
test acc=55.34%
Epoch 15/10000
188/188 - 98s - loss: 1.3590 - accuracy: 0.5395
dev acc=54.72%
Epoch 16/10000
188/188 - 99s - loss: 1.3618 - accuracy: 0.5408
dev acc=54.69%
Epoch 17/10000
188/188 - 98s - loss: 1.3588 - accuracy: 0.5399
dev acc=54.80%
Epoch 18/10000
188/188 - 98s - loss: 1.3600 - accuracy: 0.5402
dev acc=54.78%
Epoch 19/10000
188/188 - 98s - loss: 1.3581 - accuracy: 0.5401
dev acc=54.63%
time used=2451.1s
2022-05-11 17:53:02.472602: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
run_bert4keras_freeze_add.sh: line 3: $'\r': command not found
2.6.0
2.6.0
0.11.3
Namespace(batch_size=256, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_rbt4_L-4_H-768_A-12/bert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_rbt4_L-4_H-768_A-12/bert_config_rbt4.json', dropout=0.5, epochs=10000, freeze=True, gpu='2', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='bert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_rbt4_L-4_H-768_A-12/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_travel': 0, 'news_house': 1, 'news_finance': 2, 'news_military': 3, 'news_world': 4, 'news_edu': 5, 'news_game': 6, 'news_stock': 7, 'news_culture': 8, 'news_sports': 9, 'news_agriculture': 10, 'news_story': 11, 'news_entertainment': 12, 'news_car': 13, 'news_tech': 14}
index_labels_dict={0: 'news_travel', 1: 'news_house', 2: 'news_finance', 3: 'news_military', 4: 'news_world', 5: 'news_edu', 6: 'news_game', 7: 'news_stock', 8: 'news_culture', 9: 'news_sports', 10: 'news_agriculture', 11: 'news_story', 12: 'news_entertainment', 13: 'news_car', 14: 'news_tech'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-11 17:53:11.287071: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-11 17:53:12.537523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22139 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:83:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          
                                                                 Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
                                                                 Transformer-0-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
                                                                 Transformer-1-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
                                                                 Transformer-2-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
                                                                 Transformer-3-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 768)          0           Transformer-3-FeedForward-Norm[0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 768)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           11535       dropout[0][0]                    
==================================================================================================
Total params: 44,985,615
Trainable params: 11,535
Non-trainable params: 44,974,080
__________________________________________________________________________________________________
2022-05-11 17:53:14.444955: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
188/188 - 39s - loss: 1.9994 - accuracy: 0.4156
dev acc=50.97%
test acc=51.76%
Epoch 2/10000
188/188 - 34s - loss: 1.5883 - accuracy: 0.5021
dev acc=52.17%
test acc=52.72%
Epoch 3/10000
188/188 - 34s - loss: 1.5132 - accuracy: 0.5108
dev acc=52.57%
test acc=52.90%
Epoch 4/10000
188/188 - 34s - loss: 1.4854 - accuracy: 0.5148
dev acc=52.68%
test acc=53.09%
Epoch 5/10000
188/188 - 34s - loss: 1.4760 - accuracy: 0.5152
dev acc=53.04%
test acc=53.28%
Epoch 6/10000
188/188 - 34s - loss: 1.4714 - accuracy: 0.5164
dev acc=53.15%
test acc=53.34%
Epoch 7/10000
188/188 - 34s - loss: 1.4616 - accuracy: 0.5168
dev acc=53.11%
Epoch 8/10000
188/188 - 34s - loss: 1.4601 - accuracy: 0.5154
dev acc=53.28%
test acc=53.53%
Epoch 9/10000
188/188 - 34s - loss: 1.4549 - accuracy: 0.5189
dev acc=53.60%
test acc=53.46%
Epoch 10/10000
188/188 - 34s - loss: 1.4551 - accuracy: 0.5197
dev acc=53.60%
Epoch 11/10000
188/188 - 34s - loss: 1.4516 - accuracy: 0.5192
dev acc=53.65%
test acc=53.66%
Epoch 12/10000
188/188 - 34s - loss: 1.4528 - accuracy: 0.5188
dev acc=53.80%
test acc=53.63%
Epoch 13/10000
188/188 - 34s - loss: 1.4464 - accuracy: 0.5207
dev acc=53.62%
Epoch 14/10000
188/188 - 34s - loss: 1.4507 - accuracy: 0.5202
dev acc=53.75%
Epoch 15/10000
188/188 - 34s - loss: 1.4470 - accuracy: 0.5204
dev acc=53.88%
test acc=53.61%
Epoch 16/10000
188/188 - 34s - loss: 1.4478 - accuracy: 0.5202
dev acc=53.82%
Epoch 17/10000
188/188 - 34s - loss: 1.4491 - accuracy: 0.5200
dev acc=53.64%
Epoch 18/10000
188/188 - 34s - loss: 1.4485 - accuracy: 0.5193
dev acc=53.41%
Epoch 19/10000
188/188 - 34s - loss: 1.4500 - accuracy: 0.5192
dev acc=53.56%
Epoch 20/10000
188/188 - 34s - loss: 1.4465 - accuracy: 0.5194
dev acc=53.41%
time used=1003.9s
2022-05-11 18:09:50.463355: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
run_bert4keras_freeze_add.sh: line 4: $'\r': command not found
2.6.0
2.6.0
0.11.3
Namespace(batch_size=256, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_rbt6_L-6_H-768_A-12/bert_model.ckpt', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_rbt6_L-6_H-768_A-12/bert_config_rbt6.json', dropout=0.5, epochs=10000, freeze=True, gpu='2', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='bert', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/Chinese-BERT-wwm/chinese_rbt6_L-6_H-768_A-12/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_stock': 0, 'news_world': 1, 'news_tech': 2, 'news_military': 3, 'news_edu': 4, 'news_story': 5, 'news_finance': 6, 'news_entertainment': 7, 'news_car': 8, 'news_sports': 9, 'news_culture': 10, 'news_travel': 11, 'news_agriculture': 12, 'news_game': 13, 'news_house': 14}
index_labels_dict={0: 'news_stock', 1: 'news_world', 2: 'news_tech', 3: 'news_military', 4: 'news_edu', 5: 'news_story', 6: 'news_finance', 7: 'news_entertainment', 8: 'news_car', 9: 'news_sports', 10: 'news_culture', 11: 'news_travel', 12: 'news_agriculture', 13: 'news_game', 14: 'news_house'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-11 18:09:59.164735: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-11 18:10:00.255332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22139 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:83:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Position (PositionEmb (None, None, 768)    393216      Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Position[0][0]         
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          
                                                                 Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
                                                                 Transformer-0-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
                                                                 Transformer-1-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
                                                                 Transformer-2-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
                                                                 Transformer-3-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
                                                                 Transformer-4-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
                                                                 Transformer-5-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 768)          0           Transformer-5-FeedForward-Norm[0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 768)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           11535       dropout[0][0]                    
==================================================================================================
Total params: 59,161,359
Trainable params: 11,535
Non-trainable params: 59,149,824
__________________________________________________________________________________________________
2022-05-11 18:10:02.697127: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
188/188 - 57s - loss: 1.9929 - accuracy: 0.4190
dev acc=50.97%
test acc=51.62%
Epoch 2/10000
188/188 - 50s - loss: 1.5780 - accuracy: 0.5068
dev acc=52.40%
test acc=52.81%
Epoch 3/10000
188/188 - 50s - loss: 1.5032 - accuracy: 0.5122
dev acc=52.72%
test acc=53.56%
Epoch 4/10000
188/188 - 50s - loss: 1.4673 - accuracy: 0.5181
dev acc=52.74%
test acc=53.64%
Epoch 5/10000
188/188 - 50s - loss: 1.4593 - accuracy: 0.5197
dev acc=52.87%
test acc=53.66%
Epoch 6/10000
188/188 - 50s - loss: 1.4488 - accuracy: 0.5221
dev acc=52.89%
test acc=53.84%
Epoch 7/10000
188/188 - 50s - loss: 1.4469 - accuracy: 0.5208
dev acc=53.05%
test acc=53.96%
Epoch 8/10000
188/188 - 50s - loss: 1.4361 - accuracy: 0.5234
dev acc=53.20%
test acc=54.05%
Epoch 9/10000
188/188 - 50s - loss: 1.4342 - accuracy: 0.5239
dev acc=53.05%
Epoch 10/10000
188/188 - 50s - loss: 1.4343 - accuracy: 0.5263
dev acc=53.41%
test acc=53.85%
Epoch 11/10000
188/188 - 50s - loss: 1.4305 - accuracy: 0.5236
dev acc=53.28%
Epoch 12/10000
188/188 - 50s - loss: 1.4326 - accuracy: 0.5217
dev acc=53.35%
Epoch 13/10000
188/188 - 50s - loss: 1.4279 - accuracy: 0.5250
dev acc=53.30%
Epoch 14/10000
188/188 - 50s - loss: 1.4319 - accuracy: 0.5257
dev acc=53.17%
Epoch 15/10000
188/188 - 50s - loss: 1.4306 - accuracy: 0.5257
dev acc=53.39%
time used=1090.5s
2022-05-11 18:28:04.932960: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
run_bert4keras_freeze_add.sh: line 5: $'\r': command not found
run_bert4keras_freeze_add.sh: line 6: $'\r': command not found
2.6.0
2.6.0
0.11.3
Namespace(batch_size=256, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Large-WWM/model.ckpt-346400', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Large-WWM/bert_config.json', dropout=0.5, epochs=10000, freeze=True, gpu='2', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='nezha', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Large-WWM/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_world': 0, 'news_military': 1, 'news_agriculture': 2, 'news_travel': 3, 'news_house': 4, 'news_sports': 5, 'news_stock': 6, 'news_tech': 7, 'news_entertainment': 8, 'news_culture': 9, 'news_game': 10, 'news_edu': 11, 'news_finance': 12, 'news_story': 13, 'news_car': 14}
index_labels_dict={0: 'news_world', 1: 'news_military', 2: 'news_agriculture', 3: 'news_travel', 4: 'news_house', 5: 'news_sports', 6: 'news_stock', 7: 'news_tech', 8: 'news_entertainment', 9: 'news_culture', 10: 'news_game', 11: 'news_edu', 12: 'news_finance', 13: 'news_story', 14: 'news_car'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-11 18:28:13.713919: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-11 18:28:14.983088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22139 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:83:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 1024)   21635072    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 1024)   2048        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 1024)   0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 1024)   2048        Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, None, 1024)   0           Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Embedding-Relative-Position (Re (None, None, 64)     8256        Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 1024)   4198400     Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 1024)   0           Embedding-Dropout[0][0]          
                                                                 Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward (Feed (None, None, 1024)   8393728     Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward-Dropo (None, None, 1024)   0           Transformer-0-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-0-FeedForward-Add ( (None, None, 1024)   0           Transformer-0-MultiHeadSelfAttent
                                                                 Transformer-0-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-0-FeedForward-Norm  (None, None, 1024)   2048        Transformer-0-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward (Feed (None, None, 1024)   8393728     Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward-Dropo (None, None, 1024)   0           Transformer-1-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-1-FeedForward-Add ( (None, None, 1024)   0           Transformer-1-MultiHeadSelfAttent
                                                                 Transformer-1-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-1-FeedForward-Norm  (None, None, 1024)   2048        Transformer-1-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward (Feed (None, None, 1024)   8393728     Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward-Dropo (None, None, 1024)   0           Transformer-2-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-2-FeedForward-Add ( (None, None, 1024)   0           Transformer-2-MultiHeadSelfAttent
                                                                 Transformer-2-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-2-FeedForward-Norm  (None, None, 1024)   2048        Transformer-2-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward (Feed (None, None, 1024)   8393728     Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward-Dropo (None, None, 1024)   0           Transformer-3-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-3-FeedForward-Add ( (None, None, 1024)   0           Transformer-3-MultiHeadSelfAttent
                                                                 Transformer-3-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-3-FeedForward-Norm  (None, None, 1024)   2048        Transformer-3-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward (Feed (None, None, 1024)   8393728     Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward-Dropo (None, None, 1024)   0           Transformer-4-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-4-FeedForward-Add ( (None, None, 1024)   0           Transformer-4-MultiHeadSelfAttent
                                                                 Transformer-4-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-4-FeedForward-Norm  (None, None, 1024)   2048        Transformer-4-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward (Feed (None, None, 1024)   8393728     Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward-Dropo (None, None, 1024)   0           Transformer-5-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-5-FeedForward-Add ( (None, None, 1024)   0           Transformer-5-MultiHeadSelfAttent
                                                                 Transformer-5-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-5-FeedForward-Norm  (None, None, 1024)   2048        Transformer-5-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward (Feed (None, None, 1024)   8393728     Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward-Dropo (None, None, 1024)   0           Transformer-6-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-6-FeedForward-Add ( (None, None, 1024)   0           Transformer-6-MultiHeadSelfAttent
                                                                 Transformer-6-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-6-FeedForward-Norm  (None, None, 1024)   2048        Transformer-6-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward (Feed (None, None, 1024)   8393728     Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward-Dropo (None, None, 1024)   0           Transformer-7-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-7-FeedForward-Add ( (None, None, 1024)   0           Transformer-7-MultiHeadSelfAttent
                                                                 Transformer-7-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-7-FeedForward-Norm  (None, None, 1024)   2048        Transformer-7-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward (Feed (None, None, 1024)   8393728     Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward-Dropo (None, None, 1024)   0           Transformer-8-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-8-FeedForward-Add ( (None, None, 1024)   0           Transformer-8-MultiHeadSelfAttent
                                                                 Transformer-8-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-8-FeedForward-Norm  (None, None, 1024)   2048        Transformer-8-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward (Feed (None, None, 1024)   8393728     Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward-Dropo (None, None, 1024)   0           Transformer-9-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-9-FeedForward-Add ( (None, None, 1024)   0           Transformer-9-MultiHeadSelfAttent
                                                                 Transformer-9-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-9-FeedForward-Norm  (None, None, 1024)   2048        Transformer-9-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward (Fee (None, None, 1024)   8393728     Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward-Drop (None, None, 1024)   0           Transformer-10-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-10-FeedForward-Add  (None, None, 1024)   0           Transformer-10-MultiHeadSelfAtten
                                                                 Transformer-10-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-10-FeedForward-Norm (None, None, 1024)   2048        Transformer-10-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-10-FeedForward-Norm[0
                                                                 Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward (Fee (None, None, 1024)   8393728     Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward-Drop (None, None, 1024)   0           Transformer-11-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-11-FeedForward-Add  (None, None, 1024)   0           Transformer-11-MultiHeadSelfAtten
                                                                 Transformer-11-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-11-FeedForward-Norm (None, None, 1024)   2048        Transformer-11-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-12-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-11-FeedForward-Norm[0
                                                                 Transformer-11-FeedForward-Norm[0
                                                                 Transformer-11-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-12-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-12-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-12-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-11-FeedForward-Norm[0
                                                                 Transformer-12-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-12-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-12-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-12-FeedForward (Fee (None, None, 1024)   8393728     Transformer-12-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-12-FeedForward-Drop (None, None, 1024)   0           Transformer-12-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-12-FeedForward-Add  (None, None, 1024)   0           Transformer-12-MultiHeadSelfAtten
                                                                 Transformer-12-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-12-FeedForward-Norm (None, None, 1024)   2048        Transformer-12-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-13-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-12-FeedForward-Norm[0
                                                                 Transformer-12-FeedForward-Norm[0
                                                                 Transformer-12-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-13-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-13-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-13-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-12-FeedForward-Norm[0
                                                                 Transformer-13-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-13-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-13-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-13-FeedForward (Fee (None, None, 1024)   8393728     Transformer-13-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-13-FeedForward-Drop (None, None, 1024)   0           Transformer-13-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-13-FeedForward-Add  (None, None, 1024)   0           Transformer-13-MultiHeadSelfAtten
                                                                 Transformer-13-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-13-FeedForward-Norm (None, None, 1024)   2048        Transformer-13-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-14-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-13-FeedForward-Norm[0
                                                                 Transformer-13-FeedForward-Norm[0
                                                                 Transformer-13-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-14-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-14-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-14-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-13-FeedForward-Norm[0
                                                                 Transformer-14-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-14-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-14-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-14-FeedForward (Fee (None, None, 1024)   8393728     Transformer-14-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-14-FeedForward-Drop (None, None, 1024)   0           Transformer-14-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-14-FeedForward-Add  (None, None, 1024)   0           Transformer-14-MultiHeadSelfAtten
                                                                 Transformer-14-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-14-FeedForward-Norm (None, None, 1024)   2048        Transformer-14-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-15-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-14-FeedForward-Norm[0
                                                                 Transformer-14-FeedForward-Norm[0
                                                                 Transformer-14-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-15-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-15-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-15-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-14-FeedForward-Norm[0
                                                                 Transformer-15-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-15-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-15-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-15-FeedForward (Fee (None, None, 1024)   8393728     Transformer-15-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-15-FeedForward-Drop (None, None, 1024)   0           Transformer-15-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-15-FeedForward-Add  (None, None, 1024)   0           Transformer-15-MultiHeadSelfAtten
                                                                 Transformer-15-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-15-FeedForward-Norm (None, None, 1024)   2048        Transformer-15-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-16-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-15-FeedForward-Norm[0
                                                                 Transformer-15-FeedForward-Norm[0
                                                                 Transformer-15-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-16-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-16-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-16-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-15-FeedForward-Norm[0
                                                                 Transformer-16-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-16-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-16-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-16-FeedForward (Fee (None, None, 1024)   8393728     Transformer-16-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-16-FeedForward-Drop (None, None, 1024)   0           Transformer-16-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-16-FeedForward-Add  (None, None, 1024)   0           Transformer-16-MultiHeadSelfAtten
                                                                 Transformer-16-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-16-FeedForward-Norm (None, None, 1024)   2048        Transformer-16-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-17-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-16-FeedForward-Norm[0
                                                                 Transformer-16-FeedForward-Norm[0
                                                                 Transformer-16-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-17-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-17-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-17-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-16-FeedForward-Norm[0
                                                                 Transformer-17-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-17-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-17-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-17-FeedForward (Fee (None, None, 1024)   8393728     Transformer-17-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-17-FeedForward-Drop (None, None, 1024)   0           Transformer-17-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-17-FeedForward-Add  (None, None, 1024)   0           Transformer-17-MultiHeadSelfAtten
                                                                 Transformer-17-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-17-FeedForward-Norm (None, None, 1024)   2048        Transformer-17-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-18-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-17-FeedForward-Norm[0
                                                                 Transformer-17-FeedForward-Norm[0
                                                                 Transformer-17-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-18-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-18-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-18-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-17-FeedForward-Norm[0
                                                                 Transformer-18-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-18-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-18-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-18-FeedForward (Fee (None, None, 1024)   8393728     Transformer-18-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-18-FeedForward-Drop (None, None, 1024)   0           Transformer-18-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-18-FeedForward-Add  (None, None, 1024)   0           Transformer-18-MultiHeadSelfAtten
                                                                 Transformer-18-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-18-FeedForward-Norm (None, None, 1024)   2048        Transformer-18-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-19-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-18-FeedForward-Norm[0
                                                                 Transformer-18-FeedForward-Norm[0
                                                                 Transformer-18-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-19-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-19-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-19-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-18-FeedForward-Norm[0
                                                                 Transformer-19-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-19-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-19-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-19-FeedForward (Fee (None, None, 1024)   8393728     Transformer-19-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-19-FeedForward-Drop (None, None, 1024)   0           Transformer-19-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-19-FeedForward-Add  (None, None, 1024)   0           Transformer-19-MultiHeadSelfAtten
                                                                 Transformer-19-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-19-FeedForward-Norm (None, None, 1024)   2048        Transformer-19-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-20-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-19-FeedForward-Norm[0
                                                                 Transformer-19-FeedForward-Norm[0
                                                                 Transformer-19-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-20-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-20-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-20-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-19-FeedForward-Norm[0
                                                                 Transformer-20-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-20-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-20-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-20-FeedForward (Fee (None, None, 1024)   8393728     Transformer-20-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-20-FeedForward-Drop (None, None, 1024)   0           Transformer-20-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-20-FeedForward-Add  (None, None, 1024)   0           Transformer-20-MultiHeadSelfAtten
                                                                 Transformer-20-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-20-FeedForward-Norm (None, None, 1024)   2048        Transformer-20-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-21-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-20-FeedForward-Norm[0
                                                                 Transformer-20-FeedForward-Norm[0
                                                                 Transformer-20-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-21-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-21-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-21-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-20-FeedForward-Norm[0
                                                                 Transformer-21-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-21-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-21-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-21-FeedForward (Fee (None, None, 1024)   8393728     Transformer-21-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-21-FeedForward-Drop (None, None, 1024)   0           Transformer-21-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-21-FeedForward-Add  (None, None, 1024)   0           Transformer-21-MultiHeadSelfAtten
                                                                 Transformer-21-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-21-FeedForward-Norm (None, None, 1024)   2048        Transformer-21-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-22-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-21-FeedForward-Norm[0
                                                                 Transformer-21-FeedForward-Norm[0
                                                                 Transformer-21-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-22-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-22-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-22-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-21-FeedForward-Norm[0
                                                                 Transformer-22-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-22-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-22-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-22-FeedForward (Fee (None, None, 1024)   8393728     Transformer-22-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-22-FeedForward-Drop (None, None, 1024)   0           Transformer-22-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-22-FeedForward-Add  (None, None, 1024)   0           Transformer-22-MultiHeadSelfAtten
                                                                 Transformer-22-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-22-FeedForward-Norm (None, None, 1024)   2048        Transformer-22-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-23-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-22-FeedForward-Norm[0
                                                                 Transformer-22-FeedForward-Norm[0
                                                                 Transformer-22-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-23-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-23-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-23-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-22-FeedForward-Norm[0
                                                                 Transformer-23-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-23-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-23-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-23-FeedForward (Fee (None, None, 1024)   8393728     Transformer-23-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-23-FeedForward-Drop (None, None, 1024)   0           Transformer-23-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-23-FeedForward-Add  (None, None, 1024)   0           Transformer-23-MultiHeadSelfAtten
                                                                 Transformer-23-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-23-FeedForward-Norm (None, None, 1024)   2048        Transformer-23-FeedForward-Add[0]
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 1024)         0           Transformer-23-FeedForward-Norm[0
__________________________________________________________________________________________________
dropout (Dropout)               (None, 1024)         0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           15375       dropout[0][0]                    
==================================================================================================
Total params: 323,972,175
Trainable params: 15,375
Non-trainable params: 323,956,800
__________________________________________________________________________________________________
2022-05-11 18:28:23.290475: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
188/188 - 333s - loss: 2.2114 - accuracy: 0.3708
dev acc=50.92%
test acc=50.58%
Epoch 2/10000
188/188 - 312s - loss: 1.7501 - accuracy: 0.5022
dev acc=54.27%
test acc=53.32%
Epoch 3/10000
188/188 - 311s - loss: 1.5792 - accuracy: 0.5183
dev acc=54.69%
test acc=54.19%
Epoch 4/10000
188/188 - 311s - loss: 1.4977 - accuracy: 0.5263
dev acc=55.00%
test acc=54.78%
Epoch 5/10000
188/188 - 312s - loss: 1.4578 - accuracy: 0.5310
dev acc=55.08%
test acc=54.99%
Epoch 6/10000
188/188 - 311s - loss: 1.4313 - accuracy: 0.5328
dev acc=55.12%
test acc=55.00%
Epoch 7/10000
188/188 - 311s - loss: 1.4181 - accuracy: 0.5330
dev acc=55.28%
test acc=55.07%
Epoch 8/10000
188/188 - 311s - loss: 1.4119 - accuracy: 0.5340
dev acc=55.32%
test acc=55.25%
Epoch 9/10000
188/188 - 311s - loss: 1.3993 - accuracy: 0.5350
dev acc=55.47%
test acc=55.26%
Epoch 10/10000
188/188 - 311s - loss: 1.3964 - accuracy: 0.5365
dev acc=55.42%
Epoch 11/10000
188/188 - 311s - loss: 1.3918 - accuracy: 0.5389
dev acc=55.43%
Epoch 12/10000
188/188 - 311s - loss: 1.3866 - accuracy: 0.5384
dev acc=55.58%
test acc=55.36%
Epoch 13/10000
188/188 - 312s - loss: 1.3881 - accuracy: 0.5378
dev acc=55.49%
Epoch 14/10000
188/188 - 311s - loss: 1.3823 - accuracy: 0.5414
dev acc=55.66%
test acc=55.49%
Epoch 15/10000
188/188 - 311s - loss: 1.3777 - accuracy: 0.5407
dev acc=55.62%
Epoch 16/10000
188/188 - 311s - loss: 1.3823 - accuracy: 0.5410
dev acc=55.77%
test acc=55.46%
Epoch 17/10000
188/188 - 310s - loss: 1.3781 - accuracy: 0.5394
dev acc=55.60%
Epoch 18/10000
188/188 - 310s - loss: 1.3758 - accuracy: 0.5422
dev acc=55.60%
Epoch 19/10000
188/188 - 310s - loss: 1.3759 - accuracy: 0.5373
dev acc=55.72%
Epoch 20/10000
188/188 - 310s - loss: 1.3724 - accuracy: 0.5416
dev acc=55.92%
test acc=55.38%
Epoch 21/10000
188/188 - 310s - loss: 1.3701 - accuracy: 0.5416
dev acc=55.83%
Epoch 22/10000
188/188 - 310s - loss: 1.3756 - accuracy: 0.5401
dev acc=56.02%
test acc=55.69%
Epoch 23/10000
188/188 - 311s - loss: 1.3728 - accuracy: 0.5412
dev acc=56.00%
Epoch 24/10000
188/188 - 310s - loss: 1.3680 - accuracy: 0.5432
dev acc=56.00%
Epoch 25/10000
188/188 - 310s - loss: 1.3682 - accuracy: 0.5427
dev acc=56.02%
Epoch 26/10000
188/188 - 311s - loss: 1.3687 - accuracy: 0.5420
dev acc=56.07%
test acc=55.51%
Epoch 27/10000
188/188 - 310s - loss: 1.3686 - accuracy: 0.5409
dev acc=56.09%
test acc=55.59%
Epoch 28/10000
188/188 - 310s - loss: 1.3664 - accuracy: 0.5437
dev acc=56.03%
Epoch 29/10000
188/188 - 310s - loss: 1.3690 - accuracy: 0.5410
dev acc=55.90%
Epoch 30/10000
188/188 - 310s - loss: 1.3681 - accuracy: 0.5427
dev acc=55.90%
Epoch 31/10000
188/188 - 310s - loss: 1.3687 - accuracy: 0.5409
dev acc=55.96%
Epoch 32/10000
188/188 - 310s - loss: 1.3646 - accuracy: 0.5442
dev acc=55.94%
time used=12593.1s
2022-05-11 21:58:02.228378: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
run_bert4keras_freeze_add.sh: line 7: $'\r': command not found
2.6.0
2.6.0
0.11.3
Namespace(batch_size=256, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Base-WWM/model.ckpt-691689', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Base-WWM/bert_config.json', dropout=0.5, epochs=10000, freeze=True, gpu='2', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='nezha', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Base-WWM/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_culture': 0, 'news_car': 1, 'news_travel': 2, 'news_edu': 3, 'news_house': 4, 'news_game': 5, 'news_story': 6, 'news_entertainment': 7, 'news_tech': 8, 'news_sports': 9, 'news_stock': 10, 'news_agriculture': 11, 'news_finance': 12, 'news_military': 13, 'news_world': 14}
index_labels_dict={0: 'news_culture', 1: 'news_car', 2: 'news_travel', 3: 'news_edu', 4: 'news_house', 5: 'news_game', 6: 'news_story', 7: 'news_entertainment', 8: 'news_tech', 9: 'news_sports', 10: 'news_stock', 11: 'news_agriculture', 12: 'news_finance', 13: 'news_military', 14: 'news_world'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-11 21:58:10.913964: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-11 21:58:11.684010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22139 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:83:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Embedding-Relative-Position (Re (None, None, 64)     8256        Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          
                                                                 Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
                                                                 Transformer-0-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
                                                                 Transformer-1-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
                                                                 Transformer-2-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
                                                                 Transformer-3-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
                                                                 Transformer-4-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
                                                                 Transformer-5-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
                                                                 Transformer-6-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
                                                                 Transformer-7-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
                                                                 Transformer-8-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
                                                                 Transformer-9-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
                                                                 Transformer-10-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0
                                                                 Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
                                                                 Transformer-11-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 768)          0           Transformer-11-FeedForward-Norm[0
__________________________________________________________________________________________________
dropout (Dropout)               (None, 768)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           11535       dropout[0][0]                    
==================================================================================================
Total params: 101,303,631
Trainable params: 11,535
Non-trainable params: 101,292,096
__________________________________________________________________________________________________
2022-05-11 21:58:15.642864: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
188/188 - 116s - loss: 2.1672 - accuracy: 0.3900
dev acc=50.56%
test acc=51.18%
Epoch 2/10000
188/188 - 104s - loss: 1.7060 - accuracy: 0.5040
dev acc=53.50%
test acc=53.76%
Epoch 3/10000
188/188 - 104s - loss: 1.5519 - accuracy: 0.5236
dev acc=54.27%
test acc=54.40%
Epoch 4/10000
188/188 - 104s - loss: 1.4898 - accuracy: 0.5267
dev acc=55.00%
test acc=54.69%
Epoch 5/10000
188/188 - 104s - loss: 1.4583 - accuracy: 0.5317
dev acc=55.25%
test acc=55.27%
Epoch 6/10000
188/188 - 104s - loss: 1.4380 - accuracy: 0.5334
dev acc=55.42%
test acc=55.43%
Epoch 7/10000
188/188 - 104s - loss: 1.4283 - accuracy: 0.5356
dev acc=55.40%
Epoch 8/10000
188/188 - 104s - loss: 1.4203 - accuracy: 0.5361
dev acc=55.51%
test acc=55.77%
Epoch 9/10000
188/188 - 104s - loss: 1.4139 - accuracy: 0.5356
dev acc=55.64%
test acc=55.94%
Epoch 10/10000
188/188 - 104s - loss: 1.4105 - accuracy: 0.5349
dev acc=55.53%
Epoch 11/10000
188/188 - 104s - loss: 1.4056 - accuracy: 0.5346
dev acc=55.42%
Epoch 12/10000
188/188 - 104s - loss: 1.4014 - accuracy: 0.5391
dev acc=55.79%
test acc=56.05%
Epoch 13/10000
188/188 - 105s - loss: 1.4007 - accuracy: 0.5376
dev acc=55.85%
test acc=56.09%
Epoch 14/10000
188/188 - 105s - loss: 1.3999 - accuracy: 0.5391
dev acc=55.77%
Epoch 15/10000
188/188 - 105s - loss: 1.3959 - accuracy: 0.5379
dev acc=55.94%
test acc=56.09%
Epoch 16/10000
188/188 - 105s - loss: 1.3953 - accuracy: 0.5395
dev acc=56.07%
test acc=56.16%
Epoch 17/10000
188/188 - 105s - loss: 1.3940 - accuracy: 0.5397
dev acc=55.68%
Epoch 18/10000
188/188 - 105s - loss: 1.3919 - accuracy: 0.5402
dev acc=55.88%
Epoch 19/10000
188/188 - 105s - loss: 1.3928 - accuracy: 0.5390
dev acc=55.87%
Epoch 20/10000
188/188 - 105s - loss: 1.3908 - accuracy: 0.5393
dev acc=55.88%
Epoch 21/10000
188/188 - 105s - loss: 1.3926 - accuracy: 0.5393
dev acc=55.88%
time used=2963.4s
2022-05-11 22:47:29.828456: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
run_bert4keras_freeze_add.sh: line 9: $'\r': command not found
2.6.0
2.6.0
0.11.3
Namespace(batch_size=256, checkpoint_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Base/model.ckpt-900000', config_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Base/bert_config.json', dropout=0.5, epochs=10000, freeze=True, gpu='2', learning_rate=0.001, max_sent_len=None, max_sent_len_ratio=0.99971, model_type='nezha', patience=5, seed=2022, vocab_path='/data0/nfs_data/zhaoxi9/pretrained_language_model/nezha/NEZHA-Base/vocab.txt')
loading data...
train size=48024
dev size=5336
test size=10000
labels_index_dict={'news_car': 0, 'news_agriculture': 1, 'news_military': 2, 'news_travel': 3, 'news_edu': 4, 'news_entertainment': 5, 'news_sports': 6, 'news_game': 7, 'news_stock': 8, 'news_house': 9, 'news_story': 10, 'news_culture': 11, 'news_world': 12, 'news_tech': 13, 'news_finance': 14}
index_labels_dict={0: 'news_car', 1: 'news_agriculture', 2: 'news_military', 3: 'news_travel', 4: 'news_edu', 5: 'news_entertainment', 6: 'news_sports', 7: 'news_game', 8: 'news_stock', 9: 'news_house', 10: 'news_story', 11: 'news_culture', 12: 'news_world', 13: 'news_tech', 14: 'news_finance'}
max_sent_len=147
147	1
60	1
56	1
55	2
54	1
53	1
52	6
51	3
50	9
49	7
48	9
47	11
46	67
45	11
44	28
43	42
42	102
41	97
40	133
39	124
38	125
37	176
36	174
35	232
34	320
33	610
32	3435
31	2667
30	2381
29	2218
28	2257
27	2157
26	2234
25	2196
24	2305
23	2329
22	2202
21	2220
20	2013
19	2272
18	1887
17	1977
16	1768
15	1598
14	1485
13	1197
12	963
11	792
10	546
9	331
8	146
7	129
6	21
5	1
4	4
max_sent_len=50
2022-05-11 22:47:38.791541: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-11 22:47:39.989665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22139 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:83:00.0, compute capability: 6.1
Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
Input-Token (InputLayer)        [(None, None)]       0                                            
__________________________________________________________________________________________________
Input-Segment (InputLayer)      [(None, None)]       0                                            
__________________________________________________________________________________________________
Embedding-Token (Embedding)     (None, None, 768)    16226304    Input-Token[0][0]                
__________________________________________________________________________________________________
Embedding-Segment (Embedding)   (None, None, 768)    1536        Input-Segment[0][0]              
__________________________________________________________________________________________________
Embedding-Token-Segment (Add)   (None, None, 768)    0           Embedding-Token[0][0]            
                                                                 Embedding-Segment[0][0]          
__________________________________________________________________________________________________
Embedding-Norm (LayerNormalizat (None, None, 768)    1536        Embedding-Token-Segment[0][0]    
__________________________________________________________________________________________________
Embedding-Dropout (Dropout)     (None, None, 768)    0           Embedding-Norm[0][0]             
__________________________________________________________________________________________________
Embedding-Relative-Position (Re (None, None, 64)     8256        Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    2362368     Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Dropout[0][0]          
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    0           Embedding-Dropout[0][0]          
                                                                 Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward (Feed (None, None, 768)    4722432     Transformer-0-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-0-FeedForward-Dropo (None, None, 768)    0           Transformer-0-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-0-FeedForward-Add ( (None, None, 768)    0           Transformer-0-MultiHeadSelfAttent
                                                                 Transformer-0-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-0-FeedForward-Norm  (None, None, 768)    1536        Transformer-0-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-0-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    0           Transformer-0-FeedForward-Norm[0]
                                                                 Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward (Feed (None, None, 768)    4722432     Transformer-1-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-1-FeedForward-Dropo (None, None, 768)    0           Transformer-1-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-1-FeedForward-Add ( (None, None, 768)    0           Transformer-1-MultiHeadSelfAttent
                                                                 Transformer-1-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-1-FeedForward-Norm  (None, None, 768)    1536        Transformer-1-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-1-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    0           Transformer-1-FeedForward-Norm[0]
                                                                 Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward (Feed (None, None, 768)    4722432     Transformer-2-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-2-FeedForward-Dropo (None, None, 768)    0           Transformer-2-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-2-FeedForward-Add ( (None, None, 768)    0           Transformer-2-MultiHeadSelfAttent
                                                                 Transformer-2-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-2-FeedForward-Norm  (None, None, 768)    1536        Transformer-2-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-2-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    0           Transformer-2-FeedForward-Norm[0]
                                                                 Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward (Feed (None, None, 768)    4722432     Transformer-3-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-3-FeedForward-Dropo (None, None, 768)    0           Transformer-3-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-3-FeedForward-Add ( (None, None, 768)    0           Transformer-3-MultiHeadSelfAttent
                                                                 Transformer-3-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-3-FeedForward-Norm  (None, None, 768)    1536        Transformer-3-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-3-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    0           Transformer-3-FeedForward-Norm[0]
                                                                 Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward (Feed (None, None, 768)    4722432     Transformer-4-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-4-FeedForward-Dropo (None, None, 768)    0           Transformer-4-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-4-FeedForward-Add ( (None, None, 768)    0           Transformer-4-MultiHeadSelfAttent
                                                                 Transformer-4-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-4-FeedForward-Norm  (None, None, 768)    1536        Transformer-4-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-4-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    0           Transformer-4-FeedForward-Norm[0]
                                                                 Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward (Feed (None, None, 768)    4722432     Transformer-5-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-5-FeedForward-Dropo (None, None, 768)    0           Transformer-5-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-5-FeedForward-Add ( (None, None, 768)    0           Transformer-5-MultiHeadSelfAttent
                                                                 Transformer-5-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-5-FeedForward-Norm  (None, None, 768)    1536        Transformer-5-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-5-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    0           Transformer-5-FeedForward-Norm[0]
                                                                 Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward (Feed (None, None, 768)    4722432     Transformer-6-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-6-FeedForward-Dropo (None, None, 768)    0           Transformer-6-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-6-FeedForward-Add ( (None, None, 768)    0           Transformer-6-MultiHeadSelfAttent
                                                                 Transformer-6-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-6-FeedForward-Norm  (None, None, 768)    1536        Transformer-6-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-6-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    0           Transformer-6-FeedForward-Norm[0]
                                                                 Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward (Feed (None, None, 768)    4722432     Transformer-7-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-7-FeedForward-Dropo (None, None, 768)    0           Transformer-7-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-7-FeedForward-Add ( (None, None, 768)    0           Transformer-7-MultiHeadSelfAttent
                                                                 Transformer-7-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-7-FeedForward-Norm  (None, None, 768)    1536        Transformer-7-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-7-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    0           Transformer-7-FeedForward-Norm[0]
                                                                 Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward (Feed (None, None, 768)    4722432     Transformer-8-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-8-FeedForward-Dropo (None, None, 768)    0           Transformer-8-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-8-FeedForward-Add ( (None, None, 768)    0           Transformer-8-MultiHeadSelfAttent
                                                                 Transformer-8-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-8-FeedForward-Norm  (None, None, 768)    1536        Transformer-8-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    2362368     Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-8-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    0           Transformer-8-FeedForward-Norm[0]
                                                                 Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-MultiHeadSelfAtte (None, None, 768)    1536        Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward (Feed (None, None, 768)    4722432     Transformer-9-MultiHeadSelfAttent
__________________________________________________________________________________________________
Transformer-9-FeedForward-Dropo (None, None, 768)    0           Transformer-9-FeedForward[0][0]  
__________________________________________________________________________________________________
Transformer-9-FeedForward-Add ( (None, None, 768)    0           Transformer-9-MultiHeadSelfAttent
                                                                 Transformer-9-FeedForward-Dropout
__________________________________________________________________________________________________
Transformer-9-FeedForward-Norm  (None, None, 768)    1536        Transformer-9-FeedForward-Add[0][
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-9-FeedForward-Norm[0]
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    0           Transformer-9-FeedForward-Norm[0]
                                                                 Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward (Fee (None, None, 768)    4722432     Transformer-10-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-10-FeedForward-Drop (None, None, 768)    0           Transformer-10-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-10-FeedForward-Add  (None, None, 768)    0           Transformer-10-MultiHeadSelfAtten
                                                                 Transformer-10-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-10-FeedForward-Norm (None, None, 768)    1536        Transformer-10-FeedForward-Add[0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    2362368     Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Transformer-10-FeedForward-Norm[0
                                                                 Embedding-Relative-Position[0][0]
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    0           Transformer-10-FeedForward-Norm[0
                                                                 Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-MultiHeadSelfAtt (None, None, 768)    1536        Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward (Fee (None, None, 768)    4722432     Transformer-11-MultiHeadSelfAtten
__________________________________________________________________________________________________
Transformer-11-FeedForward-Drop (None, None, 768)    0           Transformer-11-FeedForward[0][0] 
__________________________________________________________________________________________________
Transformer-11-FeedForward-Add  (None, None, 768)    0           Transformer-11-MultiHeadSelfAtten
                                                                 Transformer-11-FeedForward-Dropou
__________________________________________________________________________________________________
Transformer-11-FeedForward-Norm (None, None, 768)    1536        Transformer-11-FeedForward-Add[0]
__________________________________________________________________________________________________
lambda (Lambda)                 (None, 768)          0           Transformer-11-FeedForward-Norm[0
__________________________________________________________________________________________________
dropout (Dropout)               (None, 768)          0           lambda[0][0]                     
__________________________________________________________________________________________________
dense (Dense)                   (None, 15)           11535       dropout[0][0]                    
==================================================================================================
Total params: 101,303,631
Trainable params: 11,535
Non-trainable params: 101,292,096
__________________________________________________________________________________________________
2022-05-11 22:47:43.659663: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10000
188/188 - 117s - loss: 2.0922 - accuracy: 0.4002
dev acc=51.61%
test acc=51.52%
Epoch 2/10000
188/188 - 104s - loss: 1.6428 - accuracy: 0.5050
dev acc=53.50%
test acc=53.33%
Epoch 3/10000
188/188 - 105s - loss: 1.5286 - accuracy: 0.5144
dev acc=53.94%
test acc=54.13%
Epoch 4/10000
188/188 - 105s - loss: 1.4850 - accuracy: 0.5201
dev acc=54.63%
test acc=54.59%
Epoch 5/10000
188/188 - 105s - loss: 1.4611 - accuracy: 0.5240
dev acc=54.87%
test acc=54.63%
Epoch 6/10000
188/188 - 105s - loss: 1.4471 - accuracy: 0.5259
dev acc=55.00%
test acc=55.11%
Epoch 7/10000
188/188 - 105s - loss: 1.4426 - accuracy: 0.5266
dev acc=54.99%
Epoch 8/10000
188/188 - 105s - loss: 1.4286 - accuracy: 0.5310
dev acc=55.08%
test acc=55.27%
Epoch 9/10000
188/188 - 105s - loss: 1.4293 - accuracy: 0.5285
dev acc=55.08%
Epoch 10/10000
188/188 - 105s - loss: 1.4256 - accuracy: 0.5303
dev acc=55.06%
Epoch 11/10000
188/188 - 105s - loss: 1.4211 - accuracy: 0.5284
dev acc=54.99%
Epoch 12/10000
188/188 - 105s - loss: 1.4188 - accuracy: 0.5306
dev acc=55.15%
test acc=55.23%
Epoch 13/10000
188/188 - 105s - loss: 1.4215 - accuracy: 0.5317
dev acc=55.38%
test acc=55.14%
Epoch 14/10000
188/188 - 105s - loss: 1.4211 - accuracy: 0.5303
dev acc=55.38%
Epoch 15/10000
188/188 - 105s - loss: 1.4160 - accuracy: 0.5296
dev acc=55.23%
Epoch 16/10000
188/188 - 105s - loss: 1.4193 - accuracy: 0.5326
dev acc=55.32%
Epoch 17/10000
188/188 - 105s - loss: 1.4135 - accuracy: 0.5288
dev acc=55.34%
Epoch 18/10000
188/188 - 105s - loss: 1.4165 - accuracy: 0.5319
dev acc=55.36%
time used=2507.7s
2022-05-11 23:29:21.721529: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
